{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/final_processed_h01-20200912-101538.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "social functions\n",
    "gathering\n",
    "empty streets\n",
    "interaction\n",
    "large\n",
    "no cars\n",
    "non-essential\n",
    "travel\n",
    "unnecessary\n",
    "crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['social functions' , 'gathering', 'empty streets', \n",
    "            'interaction', 'large', 'no cars', 'non-essential',\n",
    "            'travel', 'unnecessary', 'crowd',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fuzzy_m(row):\n",
    "    matches = process.extract(row['final'], keywords_final, limit=3)\n",
    "    exactMatch = matches[0][1] == 90\n",
    "    row['Match 1'] = matches[0][0]\n",
    "    row['Match 1 Score'] = matches[0][1]\n",
    "    row['Match 2'] = \"\" if exactMatch else matches[1][0]\n",
    "    row['Match 2 Score'] = \"\" if exactMatch else matches[1][1]\n",
    "    row['Match 3'] = \"\" if exactMatch else matches[2][0]\n",
    "    row['Match 3 Score'] = \"\" if exactMatch else matches[2][1]\n",
    "    return row    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "interim_sd = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_sd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_sd['Match 1 Score'] = interim_sd['Match 1 Score'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_sd[interim_sd['Match 1 Score'] == 90].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.053900e+07</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke see justin bieber pandemic go back sleep</td>\n",
       "      <td>50</td>\n",
       "      <td>empty street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.497239e+17</td>\n",
       "      <td>our intention is to make sure that evidence sc...</td>\n",
       "      <td>@TeresaCCarter2 “Our intention is to make sure...</td>\n",
       "      <td>intention make sure evidence sciencebased dat...</td>\n",
       "      <td>73</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.293830e+18</td>\n",
       "      <td>for more information contact us  mail  follow ...</td>\n",
       "      <td>For More Information contact us. \\nMail:- digi...</td>\n",
       "      <td>information contact u mail follow instagram gy...</td>\n",
       "      <td>73</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.188902e+18</td>\n",
       "      <td>uae reports 1007 new covid19 cases highest sin...</td>\n",
       "      <td>UAE reports 1,007 new Covid-19 cases, highest ...</td>\n",
       "      <td>uae report 1007 new covid19 case high since ou...</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.273830e+08</td>\n",
       "      <td>trump officials interfered with cdc reports on...</td>\n",
       "      <td>Trump officials interfered with CDC reports on...</td>\n",
       "      <td>trump official interfere cdc report covid19 po...</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1.304427e+18</td>\n",
       "      <td>6.874206e+07</td>\n",
       "      <td>why did twitter suddenly reinstate   could it ...</td>\n",
       "      <td>Why did Twitter suddenly reinstate @clif_high?...</td>\n",
       "      <td>twitter suddenly reinstate could science valid...</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>1.304671e+18</td>\n",
       "      <td>8.323244e+17</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>Denna veckas COVID-19 veckorapport från Folkhä...</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>4.446656e+09</td>\n",
       "      <td>republicans defend trump after he admitted dow...</td>\n",
       "      <td>Republicans Defend Trump After He Admitted Dow...</td>\n",
       "      <td>republican defend trump admit downplay true th...</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>1.301853e+18</td>\n",
       "      <td>3.914277e+08</td>\n",
       "      <td>the recession on the back of the governments h...</td>\n",
       "      <td>The recession on the back of the Government's ...</td>\n",
       "      <td>recession back government handle covid economi...</td>\n",
       "      <td>50</td>\n",
       "      <td>empty street</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1.304756e+18</td>\n",
       "      <td>2.215891e+09</td>\n",
       "      <td>65 catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 Catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 catholic across street 7 wear mask</td>\n",
       "      <td>67</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "0     1.304786e+18  9.053900e+07   \n",
       "1     1.304786e+18  8.497239e+17   \n",
       "2     1.304786e+18  1.293830e+18   \n",
       "3     1.304786e+18  1.188902e+18   \n",
       "4     1.304786e+18  2.273830e+08   \n",
       "...            ...           ...   \n",
       "6732  1.304427e+18  6.874206e+07   \n",
       "6733  1.304671e+18  8.323244e+17   \n",
       "6734  1.304768e+18  4.446656e+09   \n",
       "6735  1.301853e+18  3.914277e+08   \n",
       "6736  1.304756e+18  2.215891e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     our intention is to make sure that evidence sc...   \n",
       "2     for more information contact us  mail  follow ...   \n",
       "3     uae reports 1007 new covid19 cases highest sin...   \n",
       "4     trump officials interfered with cdc reports on...   \n",
       "...                                                 ...   \n",
       "6732  why did twitter suddenly reinstate   could it ...   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...   \n",
       "6734  republicans defend trump after he admitted dow...   \n",
       "6735  the recession on the back of the governments h...   \n",
       "6736  65 catholics across the street only 7 wearing ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     @TeresaCCarter2 “Our intention is to make sure...   \n",
       "2     For More Information contact us. \\nMail:- digi...   \n",
       "3     UAE reports 1,007 new Covid-19 cases, highest ...   \n",
       "4     Trump officials interfered with CDC reports on...   \n",
       "...                                                 ...   \n",
       "6732  Why did Twitter suddenly reinstate @clif_high?...   \n",
       "6733  Denna veckas COVID-19 veckorapport från Folkhä...   \n",
       "6734  Republicans Defend Trump After He Admitted Dow...   \n",
       "6735  The recession on the back of the Government's ...   \n",
       "6736  65 Catholics across the street only 7 wearing ...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "0         woke see justin bieber pandemic go back sleep           50   \n",
       "1      intention make sure evidence sciencebased dat...           73   \n",
       "2     information contact u mail follow instagram gy...           73   \n",
       "3     uae report 1007 new covid19 case high since ou...           67   \n",
       "4     trump official interfere cdc report covid19 po...           67   \n",
       "...                                                 ...          ...   \n",
       "6732  twitter suddenly reinstate could science valid...           67   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...           67   \n",
       "6734  republican defend trump admit downplay true th...           67   \n",
       "6735  recession back government handle covid economi...           50   \n",
       "6736              65 catholic across street 7 wear mask           67   \n",
       "\n",
       "     final_keyword_match  \n",
       "0           empty street  \n",
       "1            interaction  \n",
       "2            interaction  \n",
       "3                    car  \n",
       "4                    car  \n",
       "...                  ...  \n",
       "6732                 car  \n",
       "6733                 car  \n",
       "6734                 car  \n",
       "6735        empty street  \n",
       "6736                 car  \n",
       "\n",
       "[6737 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd['final_score'] = interim_sd['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.702138e+07</td>\n",
       "      <td>yet another reason to vote ⁦⁩ out like we don’...</td>\n",
       "      <td>Yet another reason to vote ⁦@realDonaldTrump⁩ ...</td>\n",
       "      <td>yet another reason vote ⁦⁩ like  already enoug...</td>\n",
       "      <td>100</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.251557e+08</td>\n",
       "      <td>the data generated so far are mostly individua...</td>\n",
       "      <td>@HardMoneyCowboy @SteveSkojec @MarkBra32931299...</td>\n",
       "      <td>data generate far mostly individual case study...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.830267e+17</td>\n",
       "      <td>i bet you wear a mask when you are in the car ...</td>\n",
       "      <td>@blondygirl1 I bet you wear a mask when you ar...</td>\n",
       "      <td>bet wear mask car home get bubble live life lo...</td>\n",
       "      <td>100</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.262011e+09</td>\n",
       "      <td>this is pelosi and others inviting people to c...</td>\n",
       "      <td>https://t.co/eqhxBOMMnn\\nTHIS IS PELOSI AND OT...</td>\n",
       "      <td>pelosi others invite people china town play vi...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.415685e+09</td>\n",
       "      <td>i really hope y’all are taking care of your sk...</td>\n",
       "      <td>I really hope y’all are taking care of your sk...</td>\n",
       "      <td>really hope  take care skin wear mask also hop...</td>\n",
       "      <td>100</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>1.221882e+18</td>\n",
       "      <td>2.361712e+09</td>\n",
       "      <td>large boulder the size of a small boulder is c...</td>\n",
       "      <td>Large boulder the size of a small boulder is c...</td>\n",
       "      <td>large boulder size small boulder completely bl...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6579</th>\n",
       "      <td>1.304706e+18</td>\n",
       "      <td>8.843692e+17</td>\n",
       "      <td>efforts must be made to reduce class sizes  bi...</td>\n",
       "      <td>Efforts must be made to reduce class sizes.\\n\\...</td>\n",
       "      <td>effort must make reduce class size big class s...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6632</th>\n",
       "      <td>1.304521e+18</td>\n",
       "      <td>1.173098e+18</td>\n",
       "      <td>the endless cycle of incarceration client rele...</td>\n",
       "      <td>The endless cycle of incarceration: Client rel...</td>\n",
       "      <td>endless cycle incarceration client release jai...</td>\n",
       "      <td>100</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>1.303462e+18</td>\n",
       "      <td>3.554202e+09</td>\n",
       "      <td>corona when it sees a large gathering but then...</td>\n",
       "      <td>Corona when it sees a large gathering but then...</td>\n",
       "      <td>corona see large gathering realises  work scho...</td>\n",
       "      <td>100</td>\n",
       "      <td>gathering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6685</th>\n",
       "      <td>1.263393e+18</td>\n",
       "      <td>7.940104e+08</td>\n",
       "      <td>the communities who are going to be scared aft...</td>\n",
       "      <td>The communities who are going to be scared aft...</td>\n",
       "      <td>community go scar lockdown lift one shield cor...</td>\n",
       "      <td>100</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "6     1.304786e+18  2.702138e+07   \n",
       "48    1.304786e+18  8.251557e+08   \n",
       "88    1.304786e+18  9.830267e+17   \n",
       "92    1.304786e+18  2.262011e+09   \n",
       "95    1.304786e+18  1.415685e+09   \n",
       "...            ...           ...   \n",
       "6572  1.221882e+18  2.361712e+09   \n",
       "6579  1.304706e+18  8.843692e+17   \n",
       "6632  1.304521e+18  1.173098e+18   \n",
       "6682  1.303462e+18  3.554202e+09   \n",
       "6685  1.263393e+18  7.940104e+08   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "6     yet another reason to vote ⁦⁩ out like we don’...   \n",
       "48    the data generated so far are mostly individua...   \n",
       "88    i bet you wear a mask when you are in the car ...   \n",
       "92    this is pelosi and others inviting people to c...   \n",
       "95    i really hope y’all are taking care of your sk...   \n",
       "...                                                 ...   \n",
       "6572  large boulder the size of a small boulder is c...   \n",
       "6579  efforts must be made to reduce class sizes  bi...   \n",
       "6632  the endless cycle of incarceration client rele...   \n",
       "6682  corona when it sees a large gathering but then...   \n",
       "6685  the communities who are going to be scared aft...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "6     Yet another reason to vote ⁦@realDonaldTrump⁩ ...   \n",
       "48    @HardMoneyCowboy @SteveSkojec @MarkBra32931299...   \n",
       "88    @blondygirl1 I bet you wear a mask when you ar...   \n",
       "92    https://t.co/eqhxBOMMnn\\nTHIS IS PELOSI AND OT...   \n",
       "95    I really hope y’all are taking care of your sk...   \n",
       "...                                                 ...   \n",
       "6572  Large boulder the size of a small boulder is c...   \n",
       "6579  Efforts must be made to reduce class sizes.\\n\\...   \n",
       "6632  The endless cycle of incarceration: Client rel...   \n",
       "6682  Corona when it sees a large gathering but then...   \n",
       "6685  The communities who are going to be scared aft...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "6     yet another reason vote ⁦⁩ like  already enoug...          100   \n",
       "48    data generate far mostly individual case study...          100   \n",
       "88    bet wear mask car home get bubble live life lo...          100   \n",
       "92    pelosi others invite people china town play vi...          100   \n",
       "95    really hope  take care skin wear mask also hop...          100   \n",
       "...                                                 ...          ...   \n",
       "6572  large boulder size small boulder completely bl...          100   \n",
       "6579  effort must make reduce class size big class s...          100   \n",
       "6632  endless cycle incarceration client release jai...          100   \n",
       "6682  corona see large gathering realises  work scho...          100   \n",
       "6685  community go scar lockdown lift one shield cor...          100   \n",
       "\n",
       "     final_keyword_match  \n",
       "6                    car  \n",
       "48                 large  \n",
       "88                   car  \n",
       "92                travel  \n",
       "95                   car  \n",
       "...                  ...  \n",
       "6572               large  \n",
       "6579               large  \n",
       "6632                 car  \n",
       "6682           gathering  \n",
       "6685                 car  \n",
       "\n",
       "[298 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd[interim_sd['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd.to_csv('interim_sd.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
