{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/final_processed_h01-20200912-101538.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.053900e+07</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke see justin bieber pandemic go back sleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.497239e+17</td>\n",
       "      <td>‚Äúour intention is to make sure that evidence s...</td>\n",
       "      <td>@TeresaCCarter2 ‚ÄúOur intention is to make sure...</td>\n",
       "      <td>‚Äú intention make sure evidence sciencebased da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.293830e+18</td>\n",
       "      <td>for more information contact us  mail  follow ...</td>\n",
       "      <td>For More Information contact us. \\nMail:- digi...</td>\n",
       "      <td>information contact u mail follow üì∑instagram g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.188902e+18</td>\n",
       "      <td>uae reports 1007 new covid19 cases highest sin...</td>\n",
       "      <td>UAE reports 1,007 new Covid-19 cases, highest ...</td>\n",
       "      <td>uae report 1007 new covid19 case high since ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.273830e+08</td>\n",
       "      <td>trump officials interfered with cdc reports on...</td>\n",
       "      <td>Trump officials interfered with CDC reports on...</td>\n",
       "      <td>trump official interfere cdc report covid19 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1.304427e+18</td>\n",
       "      <td>6.874206e+07</td>\n",
       "      <td>why did twitter suddenly reinstate   could it ...</td>\n",
       "      <td>Why did Twitter suddenly reinstate @clif_high?...</td>\n",
       "      <td>twitter suddenly reinstate could science valid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>1.304671e+18</td>\n",
       "      <td>8.323244e+17</td>\n",
       "      <td>denna veckas covid19 veckorapport fr√•n folkh√§l...</td>\n",
       "      <td>Denna veckas COVID-19 veckorapport fr√•n Folkh√§...</td>\n",
       "      <td>denna veckas covid19 veckorapport fr√•n folkh√§l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>4.446656e+09</td>\n",
       "      <td>republicans defend trump after he admitted dow...</td>\n",
       "      <td>Republicans Defend Trump After He Admitted Dow...</td>\n",
       "      <td>republican defend trump admit downplay true th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>1.301853e+18</td>\n",
       "      <td>3.914277e+08</td>\n",
       "      <td>the recession on the back of the governments h...</td>\n",
       "      <td>The recession on the back of the Government's ...</td>\n",
       "      <td>recession back government handle covid economi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1.304756e+18</td>\n",
       "      <td>2.215891e+09</td>\n",
       "      <td>65 catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 Catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 catholic across street 7 wear mask</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6737 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "0     1.304786e+18  9.053900e+07   \n",
       "1     1.304786e+18  8.497239e+17   \n",
       "2     1.304786e+18  1.293830e+18   \n",
       "3     1.304786e+18  1.188902e+18   \n",
       "4     1.304786e+18  2.273830e+08   \n",
       "...            ...           ...   \n",
       "6732  1.304427e+18  6.874206e+07   \n",
       "6733  1.304671e+18  8.323244e+17   \n",
       "6734  1.304768e+18  4.446656e+09   \n",
       "6735  1.301853e+18  3.914277e+08   \n",
       "6736  1.304756e+18  2.215891e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     ‚Äúour intention is to make sure that evidence s...   \n",
       "2     for more information contact us  mail  follow ...   \n",
       "3     uae reports 1007 new covid19 cases highest sin...   \n",
       "4     trump officials interfered with cdc reports on...   \n",
       "...                                                 ...   \n",
       "6732  why did twitter suddenly reinstate   could it ...   \n",
       "6733  denna veckas covid19 veckorapport fr√•n folkh√§l...   \n",
       "6734  republicans defend trump after he admitted dow...   \n",
       "6735  the recession on the back of the governments h...   \n",
       "6736  65 catholics across the street only 7 wearing ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     @TeresaCCarter2 ‚ÄúOur intention is to make sure...   \n",
       "2     For More Information contact us. \\nMail:- digi...   \n",
       "3     UAE reports 1,007 new Covid-19 cases, highest ...   \n",
       "4     Trump officials interfered with CDC reports on...   \n",
       "...                                                 ...   \n",
       "6732  Why did Twitter suddenly reinstate @clif_high?...   \n",
       "6733  Denna veckas COVID-19 veckorapport fr√•n Folkh√§...   \n",
       "6734  Republicans Defend Trump After He Admitted Dow...   \n",
       "6735  The recession on the back of the Government's ...   \n",
       "6736  65 Catholics across the street only 7 wearing ...   \n",
       "\n",
       "                                                  final  \n",
       "0         woke see justin bieber pandemic go back sleep  \n",
       "1     ‚Äú intention make sure evidence sciencebased da...  \n",
       "2     information contact u mail follow üì∑instagram g...  \n",
       "3     uae report 1007 new covid19 case high since ou...  \n",
       "4     trump official interfere cdc report covid19 po...  \n",
       "...                                                 ...  \n",
       "6732  twitter suddenly reinstate could science valid...  \n",
       "6733  denna veckas covid19 veckorapport fr√•n folkh√§l...  \n",
       "6734  republican defend trump admit downplay true th...  \n",
       "6735  recession back government handle covid economi...  \n",
       "6736              65 catholic across street 7 wear mask  \n",
       "\n",
       "[6737 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stay at home\n",
    "do your part\n",
    "Responsible\n",
    "home\n",
    "house\n",
    "cancel\n",
    "shutdown\n",
    "postpone\n",
    "school closure\n",
    "Closure\n",
    "business closure\n",
    "suspension\n",
    "quarantine\n",
    "lockdown\n",
    "social distance\n",
    "social distancing\n",
    "self quarantine\n",
    "isolat\n",
    "6-feet\n",
    "distance\n",
    "#clubquarantine\n",
    "#quarantinelife\n",
    "#quarantineacitivites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['stay at home' , 'do your part', 'Responsible',\n",
    "            'home', 'house', 'cancel', 'shutdown', 'postpone',\n",
    "            'school closure', 'Closure', 'business closure',\n",
    "            'suspension', 'quarantine', 'lockdown', 'social distance', \n",
    "            'social distancing', 'self quarantine', 'isolat', '6-feet',\n",
    "            'distance', '#clubquarantine', '#quarantinelife', '#quarantineacitivites']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('‚Äú').strip('‚Äú').strip('‚Äô').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_lem = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "temp=' '.join(data['keywords_lem'].tolist())\n",
    "wordcloud = WordCloud(width = 800, height = 500, background_color ='white', min_font_size = 10).generate(temp)\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
