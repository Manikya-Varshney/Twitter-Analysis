{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Data Cleaning and Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHBSrnVsmQT1"
      },
      "source": [
        "\n",
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN58fBbFo48-"
      },
      "source": [
        "# Imports for GDrive\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XssQCdN5pE03"
      },
      "source": [
        "# Mounting the drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zJK_ICLpTmX"
      },
      "source": [
        "#downloaded = drive.CreateFile({'id':'https://drive.google.com/file/d/17dnH3TDdLmxos83OTHEtXBCD5Tmu-L_k/view?usp=sharing'}) # replace the id with id of file you want to access\n",
        "#downloaded.GetContentFile('h01-20201001-20201008.zip') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOdpxl2-w7sR",
        "outputId": "94499167-2ecf-416c-c6ce-b153f5acbd91"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xtF___3xLV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "152e3328-6a9b-4d40-b40b-959df2d60dfc"
      },
      "source": [
        "import os\n",
        "os.listdir('/content/gdrive/Shared drives/') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BPPC Acads']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiUQenL10eNC"
      },
      "source": [
        "# Import statements\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import csv\n",
        "import re\n",
        "import string\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7-qNi6n_pMM"
      },
      "source": [
        "# Extract zip file\n",
        "\n",
        "def extract_zips(filename, temp_folder):\n",
        "  zip_ref = zipfile.ZipFile(filename, 'r')\n",
        "  zip_ref.extractall(temp_folder)\n",
        "  zip_ref.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHS5daIFGbLI"
      },
      "source": [
        "def create_filename(FILENAME, TEMP_FOLDER):\n",
        "  FILES_NAMES = FILENAME.split(\".\")[0].split(\"/\")[-1]\n",
        "  FILES_NAMES = FILES_NAMES.rsplit(\"-\", 1)[0]\n",
        "  # FILES_NAMES = os.path.join(TEMP_FOLDER, FILES_NAMES)\n",
        "  return FILES_NAMES"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvgg28WxGj1R"
      },
      "source": [
        "def get_date_string(FILESNAMES):\n",
        "  date_string = FILESNAMES.split(\"-\")[-1]\n",
        "  return date_string\n",
        "\n",
        "def strip_date(FILESNAMES):\n",
        "  date_string = get_date_string(FILESNAMES)\n",
        "  ob = datetime.strptime(date_string, \"%Y%m%d\")\n",
        "  date_to_analyse = ob.strftime(\"%a %b %d\")\n",
        "  return date_to_analyse"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Axem73RZAAkA"
      },
      "source": [
        "# Constants\n",
        "FILENAME = \"/content/h01-20200818-10files.zip\"\n",
        "TEMP_FOLDER = \"/tmp\"\n",
        "FILES_NAMES = create_filename(FILENAME, TEMP_FOLDER)\n",
        "date_to_analyse = strip_date(FILES_NAMES)\n",
        "# print(FILES_NAMES, date_to_analyse)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuK9Y_DSL0cL"
      },
      "source": [
        "# Keep data in english only\n",
        "def remove_other_langs(data):\n",
        "  data = data[data['lang'] == 'en'].reset_index(drop=True)\n",
        "  return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwsew-o1MzvI"
      },
      "source": [
        "# Keep specific date\n",
        "def remove_other_dates(data, date_to_analyse):\n",
        "  data = data[data['created_at'].str[:10] == date_to_analyse].reset_index(drop=True)\n",
        "  return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnpiNeSksPHD"
      },
      "source": [
        "# Creating the RT Column\n",
        "def create_rt_column(data):\n",
        "  data['RT'] = data['text'].str[:2]=='RT'\n",
        "  return data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDie85V6J4IJ"
      },
      "source": [
        "# Parse CSV data\n",
        "def parse_data_from_file(filename, date_to_analyse):\n",
        "  data = pd.read_csv(filename, index_col = None, header=0, engine = 'python')\n",
        "  data = remove_other_langs(data)\n",
        "  data = remove_other_dates(data, date_to_analyse)\n",
        "  data = create_rt_column(data)\n",
        "  return data"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oksZ2gyHLTYM"
      },
      "source": [
        "# Parse all files of the same date\n",
        "def parse_all_files(TEMP_FOLDER, FILES_NAMES, date_to_analyse):\n",
        "  files = os.listdir(TEMP_FOLDER)\n",
        "  new_data = []\n",
        "  for file in files:\n",
        "    if file.startswith(FILES_NAMES):\n",
        "      parsed_data = parse_data_from_file(os.path.join(TEMP_FOLDER, file), date_to_analyse)\n",
        "      new_data.append(parsed_data)\n",
        "  return pd.concat(new_data, axis = 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6dvi4iZuO7z"
      },
      "source": [
        "def get_text_or_extended_text(data, added_ids):\n",
        "  data[\"FINAL_TEXT\"] = np.where(data['extended_tweet_full_text'].notnull(), data[\"extended_tweet_full_text\"], data[\"text\"])\n",
        "  id = data[\"id\"].to_dict()\n",
        "  added_ids.update(id)\n",
        "  return data[\"FINAL_TEXT\"]\n",
        "\n",
        "def get_quoted_text(data, added_ids):\n",
        "  data[\"FINAL_TEXT\"] = np.where(data['QT_full_text'].notnull(), data[\"QT_full_text\"], data[\"QT_text\"])\n",
        "  added_ids.update(data[\"id\"].to_dict())\n",
        "  added_ids.update(data[\"QT_id\"].to_dict())\n",
        "  return data[\"FINAL_TEXT\"]\n",
        "\n",
        "def get_text_or_full_text_rt(data, added_ids):\n",
        "  data[\"FINAL_TEXT\"] = np.where(data['RT_full_text'].notnull(), data[\"RT_full_text\"], data[\"RT_text\"])\n",
        "  added_ids.update(data[\"id\"].to_dict())\n",
        "  added_ids.update(data[\"RT_id\"].to_dict())\n",
        "  return data[\"FINAL_TEXT\"]\n",
        "\n",
        "def get_quote_rt_full(data, added_ids):\n",
        "  data[\"FINAL_TEXT\"] = get_text_or_full_text_rt(data, added_ids) + get_quoted_text(data, added_ids)\n",
        "  return data[\"FINAL_TEXT\"]\n",
        "\n",
        "\n",
        "\n",
        "def get_quote_rt(data, is_quote, is_rt):\n",
        "  data = data.loc[(data['is_quote_tweet'] == is_quote) & (data['RT'] == is_rt)]\n",
        "\n",
        "  if not is_quote and not is_rt:\n",
        "    added_ids.update(dict(zip(data[\"id\"], data[\"is_quote_tweet\"])))\n",
        "    data[\"FINAL_TEXT\"] = np.where(data['extended_tweet_full_text'].notnull(), data[\"extended_tweet_full_text\"], data[\"text\"])\n",
        "\n",
        "  if is_quote and not is_rt:\n",
        "    data[\"FINAL_TEXT\"] = np.where(data[\"QT_id\"].isin(added_ids.keys()), get_text_or_extended_text(data, added_ids), get_quoted_text(data, added_ids))\n",
        "\n",
        "  if not is_quote and is_rt:\n",
        "    data[\"FINAL_TEXT\"] = np.where(data[\"RT_id\"].isin(added_ids.keys()), added_ids.update(data['id'].to_dict()), get_text_or_full_text_rt(data, added_ids))\n",
        "    data = data[data[\"FINAL_TEXT\"].notna()]\n",
        "\n",
        "  if is_quote and is_rt:\n",
        "    data[\"FINAL_TEXT\"] = np.where((data[\"RT_id\"].isin(added_ids.keys())) & (data[\"QT_id\"].isin(added_ids.keys())), added_ids.update(data['id'].to_dict()), None)\n",
        "    data[\"FINAL_TEXT\"] = np.where((data[\"RT_id\"].isin(added_ids.keys())) & (~data[\"QT_id\"].isin(added_ids.keys())), get_quoted_text(data, added_ids), None)\n",
        "    data[\"FINAL_TEXT\"] = np.where((~data[\"RT_id\"].isin(added_ids.keys())) & (data[\"QT_id\"].isin(added_ids.keys())), get_text_or_full_text_rt(data, added_ids), None)\n",
        "    data[\"FINAL_TEXT\"] = np.where((~data[\"RT_id\"].isin(added_ids.keys())) & (~data[\"QT_id\"].isin(added_ids.keys())), get_quote_rt_full(data, added_ids), None)\n",
        "    data = data[data[\"FINAL_TEXT\"].notna()]\n",
        "\n",
        "  return data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7R4r1VkAMtE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abda6eea-7b6c-4505-ed56-065ca41c5ff7"
      },
      "source": [
        "# Driver code\n",
        "added_ids = {}\n",
        "extract_zips(FILENAME, TEMP_FOLDER)\n",
        "data = parse_all_files(TEMP_FOLDER, FILES_NAMES, date_to_analyse)\n",
        "print(data.shape, type(data))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(112410, 80) <class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0Ah-yD2q7yD"
      },
      "source": [
        "# Check duplicates\n",
        "# print(data[\"text\"].nunique())\n",
        "# print(data[\"extended_tweet_full_text\"].nunique())\n",
        "# print(data[\"QT_full_text\"].nunique())\n",
        "# print(data[\"QT_text\"].nunique())\n",
        "# print(data[\"RT_full_text\"].nunique())\n",
        "# print(data[\"RT_text\"].nunique())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMUvsAaLvwK-",
        "outputId": "9adbbc7b-4119-4729-8145-99144c93e5ea"
      },
      "source": [
        "non_quote_non_rt = get_quote_rt(data, False, False)\n",
        "print(non_quote_non_rt[\"FINAL_TEXT\"], non_quote_non_rt.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        can we wear clone helmets instead of masks to ...\n",
            "11       SC Senate to reconvene in Sept. to discuss COV...\n",
            "13       @JohnAvlon During the COVID-19 crisis, Pres. T...\n",
            "17       We just gonna act like @JamesStormBrand wasn’t...\n",
            "18       The COVID-19 pandemic has created unprecedente...\n",
            "                               ...                        \n",
            "10874    #ReTurkey heading back to Hisaronu for 7th tim...\n",
            "10876    @MollyJongFast SHE was wrong about the CV deat...\n",
            "10880    \"States with strict coronavirus lockdowns seem...\n",
            "10882    @adamamin Does this mean that in mid-June of n...\n",
            "10884    @ClayTravis @Outkick More evidence the Coronab...\n",
            "Name: FINAL_TEXT, Length: 28689, dtype: object (28689, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntCphckKvwBC",
        "outputId": "2ed4f102-b5f3-4029-dc59-877f0fe30e36"
      },
      "source": [
        "quote_non_rt = get_quote_rt(data, True, False)\n",
        "print(quote_non_rt[\"FINAL_TEXT\"], quote_non_rt.shape)"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2        “Our forecast for the US economy ... reflects ...\n",
            "3        Miami Dade’s antiquated storm drain system dum...\n",
            "19       Our Department will be opening up many of its ...\n",
            "31       I’m on a call with @SenBobCasey and @PAAttorne...\n",
            "32       my bf never missed a apt❤️ except for today ca...\n",
            "                               ...                        \n",
            "10800    Police are preparing to launch their aerial ar...\n",
            "10813    Mike Lindell, creator of MyPillow, is promotin...\n",
            "10820    Rolling live coverage of the new restrictions ...\n",
            "10847                               Wear\\nA\\nPhucking mask\n",
            "10885    Like the Trump administration, Florida has emb...\n",
            "Name: FINAL_TEXT, Length: 9171, dtype: object (9171, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puDSndZUwJvE",
        "outputId": "71045fbd-a8a1-495a-d9d8-fee4b5f1287a"
      },
      "source": [
        "quote_rt = get_quote_rt(data, True, True)\n",
        "print(quote_rt[\"FINAL_TEXT\"], quote_rt.shape)"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1        .@AndrewCuomo, thank you for your leadership a...\n",
            "4        Gold Reef City  would make the money they’ve l...\n",
            "7        North Carolina is now reporting they OVERCOUNT...\n",
            "8        Data shows a low % of children in single paren...\n",
            "9        Watch @iamCardiB and @JoeBiden talk police bru...\n",
            "                               ...                        \n",
            "10849    Ok, listen to this guy Carlos Piccata. \\n\"I'm ...\n",
            "10850    Police are preparing to launch their aerial ar...\n",
            "10871    UPDATE: Teachers in Arizona have staged a “sic...\n",
            "10873    We've seen a high volume of music creators dis...\n",
            "10878    'Anyone who's following COVID and its transmis...\n",
            "Name: FINAL_TEXT, Length: 18227, dtype: object (18227, 81)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrWIUjEHwJsc",
        "outputId": "bf5b7073-fa5f-4658-b272-502fffef4c4c"
      },
      "source": [
        "non_quote_rt = get_quote_rt(data, False, True)\n",
        "print(non_quote_rt[\"FINAL_TEXT\"], non_quote_rt.shape)"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5        Me in Quarantine vs the story I'll tell my gra...\n",
            "6        Trust us. This time the data is good.\\n\\n2020,...\n",
            "10       I can’t believe China is partying and America ...\n",
            "12       Me in Quarantine vs the story I'll tell my gra...\n",
            "15       pregnancy and corona really neck and neck for ...\n",
            "                               ...                        \n",
            "10877    27 times Trump said the coronavirus would go a...\n",
            "10881    It's starting to look as if Sweden got the bes...\n",
            "10883    What is normal? Was everything we knew before ...\n",
            "10886    OMG, college kids are going to test positive f...\n",
            "10887    Anderson Cooper tears into the MyPillow guy fo...\n",
            "Name: FINAL_TEXT, Length: 49887, dtype: object (49887, 81)\n"
          ]
        }
      ]
    }
  ]
}