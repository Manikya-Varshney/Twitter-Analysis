{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/final_processed_data/final_processed_april01.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Flatten the curve\n",
    "Slow the spread\n",
    "slow transmission\n",
    "protect\n",
    "save\n",
    "#stayhomesavelives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['Flatten the curve' , 'Slow the spread', 'slow transmission', \n",
    "            'protect', 'save', '#stayhomesavelives']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_purp = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28433993</td>\n",
       "      <td>As Chicago households fill out 2020 census dur...</td>\n",
       "      <td>chicago household fill out 2020 census coronav...</td>\n",
       "      <td>57</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101043870</td>\n",
       "      <td>Most of the press corps is very busy covering ...</td>\n",
       "      <td>the press corp busy cover the really important...</td>\n",
       "      <td>57</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16475267</td>\n",
       "      <td>@realDonaldTrump Mar 10–he was very specific: ...</td>\n",
       "      <td>mar 10–he specific  google 1700 engineer work ...</td>\n",
       "      <td>50</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16475267</td>\n",
       "      <td>@realDonaldTrump , You were caustic &amp;amp; sarc...</td>\n",
       "      <td>caustic amp sarcastic the rollout  come even f...</td>\n",
       "      <td>50</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345397708</td>\n",
       "      <td>Florida nears 8,000 coronavirus cases, as stat...</td>\n",
       "      <td>florida nears 8000 coronavirus case state repo...</td>\n",
       "      <td>50</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16185</th>\n",
       "      <td>751644712570847236</td>\n",
       "      <td>If in 1938 Turkey’s government could produce a...</td>\n",
       "      <td>1938 turkey  government could produce health m...</td>\n",
       "      <td>57</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>286628737</td>\n",
       "      <td>Sandy Medford was a friend of my family for de...</td>\n",
       "      <td>sandy medford friend family decade suspect hea...</td>\n",
       "      <td>59</td>\n",
       "      <td>stayhomesavelives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16187</th>\n",
       "      <td>361010205</td>\n",
       "      <td>One month ago Trump claimed the number of Amer...</td>\n",
       "      <td>one month ago trump claimed the number america...</td>\n",
       "      <td>59</td>\n",
       "      <td>flatten the curve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16188</th>\n",
       "      <td>481389842</td>\n",
       "      <td>Yes. This. Especially if a substantial proport...</td>\n",
       "      <td>yes especially substantial proportion workforc...</td>\n",
       "      <td>57</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16189</th>\n",
       "      <td>11347222</td>\n",
       "      <td>I'm sticking to my original lowball prediction...</td>\n",
       "      <td>im stick to original lowball prediction at lea...</td>\n",
       "      <td>71</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16190 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                                     text_duplicate  \\\n",
       "0                28433993  As Chicago households fill out 2020 census dur...   \n",
       "1               101043870  Most of the press corps is very busy covering ...   \n",
       "2                16475267  @realDonaldTrump Mar 10–he was very specific: ...   \n",
       "3                16475267  @realDonaldTrump , You were caustic &amp; sarc...   \n",
       "4               345397708  Florida nears 8,000 coronavirus cases, as stat...   \n",
       "...                   ...                                                ...   \n",
       "16185  751644712570847236  If in 1938 Turkey’s government could produce a...   \n",
       "16186           286628737  Sandy Medford was a friend of my family for de...   \n",
       "16187           361010205  One month ago Trump claimed the number of Amer...   \n",
       "16188           481389842  Yes. This. Especially if a substantial proport...   \n",
       "16189            11347222  I'm sticking to my original lowball prediction...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      chicago household fill out 2020 census coronav...           57   \n",
       "1      the press corp busy cover the really important...           57   \n",
       "2      mar 10–he specific  google 1700 engineer work ...           50   \n",
       "3      caustic amp sarcastic the rollout  come even f...           50   \n",
       "4      florida nears 8000 coronavirus case state repo...           50   \n",
       "...                                                  ...          ...   \n",
       "16185  1938 turkey  government could produce health m...           57   \n",
       "16186  sandy medford friend family decade suspect hea...           59   \n",
       "16187  one month ago trump claimed the number america...           59   \n",
       "16188  yes especially substantial proportion workforc...           57   \n",
       "16189  im stick to original lowball prediction at lea...           71   \n",
       "\n",
       "      final_keyword_match  \n",
       "0                 protect  \n",
       "1                 protect  \n",
       "2                    save  \n",
       "3                    save  \n",
       "4                    save  \n",
       "...                   ...  \n",
       "16185             protect  \n",
       "16186   stayhomesavelives  \n",
       "16187   flatten the curve  \n",
       "16188             protect  \n",
       "16189             protect  \n",
       "\n",
       "[16190 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_purp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_purp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_purp['final_score'] = interim_purp['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_purp = interim_purp[interim_purp['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>823231231605243904</td>\n",
       "      <td>@Lyramydog True.\\nBut the MILITARY is no longe...</td>\n",
       "      <td>true the military no longer protect the wh no ...</td>\n",
       "      <td>100</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>966829153</td>\n",
       "      <td>This is infuriating!!! Such bullshit that an a...</td>\n",
       "      <td>infuriate bullshit antiquate policy would uphe...</td>\n",
       "      <td>100</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1005508952036016132</td>\n",
       "      <td>@CDCgov @GovEvers \\n\\nReminder:\\n\\n#BrendanDas...</td>\n",
       "      <td>reminder brendandassey innocent help  already ...</td>\n",
       "      <td>100</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>950187618</td>\n",
       "      <td>*Wellness check!*\\nFirst— Shout out to all the...</td>\n",
       "      <td>wellness check first shout out to the essentia...</td>\n",
       "      <td>100</td>\n",
       "      <td>stayhomesavelives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1098553952369426434</td>\n",
       "      <td>COVID-19 is enough of a threat itself, and the...</td>\n",
       "      <td>covid19 enough threat the result spread lethal...</td>\n",
       "      <td>100</td>\n",
       "      <td>slow the spread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16097</th>\n",
       "      <td>96454964</td>\n",
       "      <td>Praying that our healthcare workers, on the fr...</td>\n",
       "      <td>pray healthcare worker the frontlines the figh...</td>\n",
       "      <td>100</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16130</th>\n",
       "      <td>2693631704</td>\n",
       "      <td>@GovRonDeSantis shut down Florida.  Save lives...</td>\n",
       "      <td>shut florida save life  your constituent voter...</td>\n",
       "      <td>100</td>\n",
       "      <td>save</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16143</th>\n",
       "      <td>892924216412123137</td>\n",
       "      <td>Life as a physician during COVID-19 pandemic. ...</td>\n",
       "      <td>life physician covid19 pandemic aprilfoolsday ...</td>\n",
       "      <td>100</td>\n",
       "      <td>stayhomesavelives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16155</th>\n",
       "      <td>700473181308481536</td>\n",
       "      <td>@ASRA_Society @ESRA_Society \\n\\n#COVIDBlocks\\n...</td>\n",
       "      <td>covidblocks choose the right procedure vigilan...</td>\n",
       "      <td>100</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16156</th>\n",
       "      <td>396214595</td>\n",
       "      <td>Trump sent workers without protection or train...</td>\n",
       "      <td>trump sent worker without protection training ...</td>\n",
       "      <td>100</td>\n",
       "      <td>protect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                                     text_duplicate  \\\n",
       "54      823231231605243904  @Lyramydog True.\\nBut the MILITARY is no longe...   \n",
       "273              966829153  This is infuriating!!! Such bullshit that an a...   \n",
       "303    1005508952036016132  @CDCgov @GovEvers \\n\\nReminder:\\n\\n#BrendanDas...   \n",
       "331              950187618  *Wellness check!*\\nFirst— Shout out to all the...   \n",
       "435    1098553952369426434  COVID-19 is enough of a threat itself, and the...   \n",
       "...                    ...                                                ...   \n",
       "16097             96454964  Praying that our healthcare workers, on the fr...   \n",
       "16130           2693631704  @GovRonDeSantis shut down Florida.  Save lives...   \n",
       "16143   892924216412123137  Life as a physician during COVID-19 pandemic. ...   \n",
       "16155   700473181308481536  @ASRA_Society @ESRA_Society \\n\\n#COVIDBlocks\\n...   \n",
       "16156            396214595  Trump sent workers without protection or train...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "54     true the military no longer protect the wh no ...          100   \n",
       "273    infuriate bullshit antiquate policy would uphe...          100   \n",
       "303    reminder brendandassey innocent help  already ...          100   \n",
       "331    wellness check first shout out to the essentia...          100   \n",
       "435    covid19 enough threat the result spread lethal...          100   \n",
       "...                                                  ...          ...   \n",
       "16097  pray healthcare worker the frontlines the figh...          100   \n",
       "16130  shut florida save life  your constituent voter...          100   \n",
       "16143  life physician covid19 pandemic aprilfoolsday ...          100   \n",
       "16155  covidblocks choose the right procedure vigilan...          100   \n",
       "16156  trump sent worker without protection training ...          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "54                protect  \n",
       "273                  save  \n",
       "303               protect  \n",
       "331     stayhomesavelives  \n",
       "435       slow the spread  \n",
       "...                   ...  \n",
       "16097                save  \n",
       "16130                save  \n",
       "16143   stayhomesavelives  \n",
       "16155             protect  \n",
       "16156             protect  \n",
       "\n",
       "[388 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_purp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_purp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.023965410747374922\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
