{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/Test Data/final_processed_april01.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "social functions\n",
    "gathering\n",
    "empty streets\n",
    "interaction\n",
    "large\n",
    "no cars\n",
    "non-essential\n",
    "travel\n",
    "unnecessary\n",
    "crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['social functions' , 'gathering', 'empty streets', \n",
    "            'interaction', 'large', 'no cars', 'non-essential',\n",
    "            'travel', 'unnecessary', 'crowd',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "data['final'].replace(\"\", nan_value, inplace=True)\n",
    "data.dropna(subset = [\"final\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '‍']\n"
     ]
    }
   ],
   "source": [
    "interim_sd = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.843399e+07</td>\n",
       "      <td>As Chicago households fill out 2020 census dur...</td>\n",
       "      <td>chicago household fill out 2020 census coronav...</td>\n",
       "      <td>55</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.010439e+08</td>\n",
       "      <td>Most of the press corps is very busy covering ...</td>\n",
       "      <td>the press corp busy cover the really important...</td>\n",
       "      <td>67</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump Mar 10–he was very specific: ...</td>\n",
       "      <td>mar 10–he specific  google 1700 engineer work ...</td>\n",
       "      <td>60</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump , You were caustic &amp;amp; sarc...</td>\n",
       "      <td>caustic amp sarcastic the rollout  come even f...</td>\n",
       "      <td>73</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.453977e+08</td>\n",
       "      <td>Florida nears 8,000 coronavirus cases, as stat...</td>\n",
       "      <td>florida nears 8000 coronavirus case state repo...</td>\n",
       "      <td>60</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>9.832288e+17</td>\n",
       "      <td>#SierraLeone has registered its index case of ...</td>\n",
       "      <td>sierraleone register index case covid19 from d...</td>\n",
       "      <td>67</td>\n",
       "      <td>gathering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16921</th>\n",
       "      <td>1.856380e+07</td>\n",
       "      <td>KTAR News reporter @TaylorKinnerup gives a cor...</td>\n",
       "      <td>ktar news reporter give coronavirus update ari...</td>\n",
       "      <td>60</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16922</th>\n",
       "      <td>9.186279e+08</td>\n",
       "      <td>Part of a 1938 public health map: https://t.co...</td>\n",
       "      <td>part 1938 public health map</td>\n",
       "      <td>40</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16923</th>\n",
       "      <td>1.240031e+18</td>\n",
       "      <td>While the resourcefulness and hustle shown by ...</td>\n",
       "      <td>the resourcefulness hustle show many to produc...</td>\n",
       "      <td>60</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16924</th>\n",
       "      <td>3.223426e+09</td>\n",
       "      <td>Six days ago, there were 13,355 new coronaviru...</td>\n",
       "      <td>six day ago 13355 new coronavirus case daily t...</td>\n",
       "      <td>60</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16925 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "0      2.843399e+07  As Chicago households fill out 2020 census dur...   \n",
       "1      1.010439e+08  Most of the press corps is very busy covering ...   \n",
       "2      1.647527e+07  @realDonaldTrump Mar 10–he was very specific: ...   \n",
       "3      1.647527e+07  @realDonaldTrump , You were caustic &amp; sarc...   \n",
       "4      3.453977e+08  Florida nears 8,000 coronavirus cases, as stat...   \n",
       "...             ...                                                ...   \n",
       "16920  9.832288e+17  #SierraLeone has registered its index case of ...   \n",
       "16921  1.856380e+07  KTAR News reporter @TaylorKinnerup gives a cor...   \n",
       "16922  9.186279e+08  Part of a 1938 public health map: https://t.co...   \n",
       "16923  1.240031e+18  While the resourcefulness and hustle shown by ...   \n",
       "16924  3.223426e+09  Six days ago, there were 13,355 new coronaviru...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      chicago household fill out 2020 census coronav...           55   \n",
       "1      the press corp busy cover the really important...           67   \n",
       "2      mar 10–he specific  google 1700 engineer work ...           60   \n",
       "3      caustic amp sarcastic the rollout  come even f...           73   \n",
       "4      florida nears 8000 coronavirus case state repo...           60   \n",
       "...                                                  ...          ...   \n",
       "16920  sierraleone register index case covid19 from d...           67   \n",
       "16921  ktar news reporter give coronavirus update ari...           60   \n",
       "16922                        part 1938 public health map           40   \n",
       "16923  the resourcefulness hustle show many to produc...           60   \n",
       "16924  six day ago 13355 new coronavirus case daily t...           60   \n",
       "\n",
       "      final_keyword_match  \n",
       "0             interaction  \n",
       "1                  travel  \n",
       "2                   large  \n",
       "3             interaction  \n",
       "4                   crowd  \n",
       "...                   ...  \n",
       "16920           gathering  \n",
       "16921               large  \n",
       "16922               large  \n",
       "16923               large  \n",
       "16924               crowd  \n",
       "\n",
       "[16925 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_sd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd['final_score'] = interim_sd['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd = interim_sd[interim_sd['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3.185928e+08</td>\n",
       "      <td>Governor DeSantis, STOP caving to politics..li...</td>\n",
       "      <td>governor desantis stop cave to politicslisten ...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.167670e+07</td>\n",
       "      <td>Coronavirus has led to sweeping travel restric...</td>\n",
       "      <td>coronavirus lead to sweep travel restriction a...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2.508913e+08</td>\n",
       "      <td>‼️ Tomorrow at 8:45 am., I will be interview b...</td>\n",
       "      <td>‼ tomorrow at 845 interview 10 covid19 virus i...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>3.354388e+09</td>\n",
       "      <td>Cities that have stay-at-home orders should al...</td>\n",
       "      <td>city stayathome order also schedule allow the ...</td>\n",
       "      <td>100</td>\n",
       "      <td>nonessential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2.851826e+08</td>\n",
       "      <td>Inoculum dose is very important. Small exposur...</td>\n",
       "      <td>inoculum dose important small exposure v large...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16652</th>\n",
       "      <td>2.507388e+07</td>\n",
       "      <td>My Administration is helping U.S. auto workers...</td>\n",
       "      <td>administration help u auto worker replace the ...</td>\n",
       "      <td>100</td>\n",
       "      <td>unnecessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16685</th>\n",
       "      <td>9.503360e+08</td>\n",
       "      <td>@Airbnb @AirbnbHelp went from offering full re...</td>\n",
       "      <td>go from offering full refund to offering parti...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16821</th>\n",
       "      <td>1.576901e+07</td>\n",
       "      <td>@cnnbrk ask about spring break travel. #corona...</td>\n",
       "      <td>ask spring break travel coronavirus</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16822</th>\n",
       "      <td>1.576901e+07</td>\n",
       "      <td>Keep reading about the possibility of cancelli...</td>\n",
       "      <td>keep reading the possibility cancel olympics d...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>1.737689e+07</td>\n",
       "      <td>Right-wing evangelist Jonathan Shuttlesworth, ...</td>\n",
       "      <td>rightwing evangelist jonathan shuttlesworth cl...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "153    3.185928e+08  Governor DeSantis, STOP caving to politics..li...   \n",
       "196    3.167670e+07  Coronavirus has led to sweeping travel restric...   \n",
       "275    2.508913e+08  ‼️ Tomorrow at 8:45 am., I will be interview b...   \n",
       "365    3.354388e+09  Cities that have stay-at-home orders should al...   \n",
       "410    2.851826e+08  Inoculum dose is very important. Small exposur...   \n",
       "...             ...                                                ...   \n",
       "16652  2.507388e+07  My Administration is helping U.S. auto workers...   \n",
       "16685  9.503360e+08  @Airbnb @AirbnbHelp went from offering full re...   \n",
       "16821  1.576901e+07  @cnnbrk ask about spring break travel. #corona...   \n",
       "16822  1.576901e+07  Keep reading about the possibility of cancelli...   \n",
       "16894  1.737689e+07  Right-wing evangelist Jonathan Shuttlesworth, ...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "153    governor desantis stop cave to politicslisten ...          100   \n",
       "196    coronavirus lead to sweep travel restriction a...          100   \n",
       "275    ‼ tomorrow at 845 interview 10 covid19 virus i...          100   \n",
       "365    city stayathome order also schedule allow the ...          100   \n",
       "410    inoculum dose important small exposure v large...          100   \n",
       "...                                                  ...          ...   \n",
       "16652  administration help u auto worker replace the ...          100   \n",
       "16685  go from offering full refund to offering parti...          100   \n",
       "16821                ask spring break travel coronavirus          100   \n",
       "16822  keep reading the possibility cancel olympics d...          100   \n",
       "16894  rightwing evangelist jonathan shuttlesworth cl...          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "153                 large  \n",
       "196                travel  \n",
       "275                 large  \n",
       "365          nonessential  \n",
       "410                 large  \n",
       "...                   ...  \n",
       "16652         unnecessary  \n",
       "16685              travel  \n",
       "16821              travel  \n",
       "16822              travel  \n",
       "16894               large  \n",
       "\n",
       "[213 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_sd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01258493353028065\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
