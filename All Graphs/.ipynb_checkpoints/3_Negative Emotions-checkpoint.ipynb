{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/Test Data/final_processed_april01.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bored\n",
    "lonely\n",
    "stress\n",
    "anxiety\n",
    "scared\n",
    "worry\n",
    "end\n",
    "cabin fever\n",
    "#sideeffectsofquarantinelife\n",
    "tissue paper\n",
    "toilet paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['bored' , 'lonely', 'stress', \n",
    "            'anxiety', 'scared', 'worry', 'end', 'cabin fever',\n",
    "            '#sideeffectsofquarantinelife', 'tissue paper', 'toilet paper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "data['final'].replace(\"\", nan_value, inplace=True)\n",
    "data.dropna(subset = [\"final\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '‍']\n"
     ]
    }
   ],
   "source": [
    "interim_ne = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.843399e+07</td>\n",
       "      <td>As Chicago households fill out 2020 census dur...</td>\n",
       "      <td>chicago household fill out 2020 census coronav...</td>\n",
       "      <td>75</td>\n",
       "      <td>bore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.010439e+08</td>\n",
       "      <td>Most of the press corps is very busy covering ...</td>\n",
       "      <td>the press corp busy cover the really important...</td>\n",
       "      <td>50</td>\n",
       "      <td>bore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump Mar 10–he was very specific: ...</td>\n",
       "      <td>mar 10–he specific  google 1700 engineer work ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump , You were caustic &amp;amp; sarc...</td>\n",
       "      <td>caustic amp sarcastic the rollout  come even f...</td>\n",
       "      <td>75</td>\n",
       "      <td>scar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.453977e+08</td>\n",
       "      <td>Florida nears 8,000 coronavirus cases, as stat...</td>\n",
       "      <td>florida nears 8000 coronavirus case state repo...</td>\n",
       "      <td>67</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>9.832288e+17</td>\n",
       "      <td>#SierraLeone has registered its index case of ...</td>\n",
       "      <td>sierraleone register index case covid19 from d...</td>\n",
       "      <td>67</td>\n",
       "      <td>lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16921</th>\n",
       "      <td>1.856380e+07</td>\n",
       "      <td>KTAR News reporter @TaylorKinnerup gives a cor...</td>\n",
       "      <td>ktar news reporter give coronavirus update ari...</td>\n",
       "      <td>67</td>\n",
       "      <td>stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16922</th>\n",
       "      <td>9.186279e+08</td>\n",
       "      <td>Part of a 1938 public health map: https://t.co...</td>\n",
       "      <td>part 1938 public health map</td>\n",
       "      <td>45</td>\n",
       "      <td>toilet paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16923</th>\n",
       "      <td>1.240031e+18</td>\n",
       "      <td>While the resourcefulness and hustle shown by ...</td>\n",
       "      <td>the resourcefulness hustle show many to produc...</td>\n",
       "      <td>67</td>\n",
       "      <td>stress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16924</th>\n",
       "      <td>3.223426e+09</td>\n",
       "      <td>Six days ago, there were 13,355 new coronaviru...</td>\n",
       "      <td>six day ago 13355 new coronavirus case daily t...</td>\n",
       "      <td>67</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16925 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "0      2.843399e+07  As Chicago households fill out 2020 census dur...   \n",
       "1      1.010439e+08  Most of the press corps is very busy covering ...   \n",
       "2      1.647527e+07  @realDonaldTrump Mar 10–he was very specific: ...   \n",
       "3      1.647527e+07  @realDonaldTrump , You were caustic &amp; sarc...   \n",
       "4      3.453977e+08  Florida nears 8,000 coronavirus cases, as stat...   \n",
       "...             ...                                                ...   \n",
       "16920  9.832288e+17  #SierraLeone has registered its index case of ...   \n",
       "16921  1.856380e+07  KTAR News reporter @TaylorKinnerup gives a cor...   \n",
       "16922  9.186279e+08  Part of a 1938 public health map: https://t.co...   \n",
       "16923  1.240031e+18  While the resourcefulness and hustle shown by ...   \n",
       "16924  3.223426e+09  Six days ago, there were 13,355 new coronaviru...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      chicago household fill out 2020 census coronav...           75   \n",
       "1      the press corp busy cover the really important...           50   \n",
       "2      mar 10–he specific  google 1700 engineer work ...          100   \n",
       "3      caustic amp sarcastic the rollout  come even f...           75   \n",
       "4      florida nears 8000 coronavirus case state repo...           67   \n",
       "...                                                  ...          ...   \n",
       "16920  sierraleone register index case covid19 from d...           67   \n",
       "16921  ktar news reporter give coronavirus update ari...           67   \n",
       "16922                        part 1938 public health map           45   \n",
       "16923  the resourcefulness hustle show many to produc...           67   \n",
       "16924  six day ago 13355 new coronavirus case daily t...           67   \n",
       "\n",
       "      final_keyword_match  \n",
       "0                    bore  \n",
       "1                    bore  \n",
       "2                     end  \n",
       "3                    scar  \n",
       "4                     end  \n",
       "...                   ...  \n",
       "16920              lonely  \n",
       "16921              stress  \n",
       "16922        toilet paper  \n",
       "16923              stress  \n",
       "16924                 end  \n",
       "\n",
       "[16925 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_ne.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ne['final_score'] = interim_ne['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ne = interim_ne[interim_ne['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16475267.0</td>\n",
       "      <td>@realDonaldTrump Mar 10–he was very specific: ...</td>\n",
       "      <td>mar 10–he specific  google 1700 engineer work ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>394499101.0</td>\n",
       "      <td>AOC slams Cuomo's decision to suspend New York...</td>\n",
       "      <td>aoc slam cuomos decision to suspend new yorker...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>95027069.0</td>\n",
       "      <td>How are we at #jpcarpet spending our #quaranti...</td>\n",
       "      <td>at jpcarpet spending quarantine building close...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15201225.0</td>\n",
       "      <td>NEW BLOG! \"10 Self-Care Tips during a Stay-At-...</td>\n",
       "      <td>new blog 10 selfcare tip stayathome order frie...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>7919632.0</td>\n",
       "      <td>This column by @karaswisher is the column my n...</td>\n",
       "      <td>column the column niece boyfriend need to read...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16815</th>\n",
       "      <td>39344374.0</td>\n",
       "      <td>My good friend &amp;amp; hunting buddy @SteveDaine...</td>\n",
       "      <td>good friend amp hunt buddy need help midnight ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>16614351.0</td>\n",
       "      <td>My wife is making masks but in true Jane fashi...</td>\n",
       "      <td>wife make mask true jane fashion make stylish ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16860</th>\n",
       "      <td>612473.0</td>\n",
       "      <td>James Corden says he's been struggling with \"i...</td>\n",
       "      <td>james corden say he struggle incredible spike ...</td>\n",
       "      <td>100</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16874</th>\n",
       "      <td>939091.0</td>\n",
       "      <td>Tonight marks our biggest public end-of-quarte...</td>\n",
       "      <td>tonight mark big public endofquarter deadline ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16894</th>\n",
       "      <td>17376893.0</td>\n",
       "      <td>Right-wing evangelist Jonathan Shuttlesworth, ...</td>\n",
       "      <td>rightwing evangelist jonathan shuttlesworth cl...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_id                                     text_duplicate  \\\n",
       "2       16475267.0  @realDonaldTrump Mar 10–he was very specific: ...   \n",
       "10     394499101.0  AOC slams Cuomo's decision to suspend New York...   \n",
       "18      95027069.0  How are we at #jpcarpet spending our #quaranti...   \n",
       "41      15201225.0  NEW BLOG! \"10 Self-Care Tips during a Stay-At-...   \n",
       "92       7919632.0  This column by @karaswisher is the column my n...   \n",
       "...            ...                                                ...   \n",
       "16815   39344374.0  My good friend &amp; hunting buddy @SteveDaine...   \n",
       "16849   16614351.0  My wife is making masks but in true Jane fashi...   \n",
       "16860     612473.0  James Corden says he's been struggling with \"i...   \n",
       "16874     939091.0  Tonight marks our biggest public end-of-quarte...   \n",
       "16894   17376893.0  Right-wing evangelist Jonathan Shuttlesworth, ...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "2      mar 10–he specific  google 1700 engineer work ...          100   \n",
       "10     aoc slam cuomos decision to suspend new yorker...          100   \n",
       "18     at jpcarpet spending quarantine building close...          100   \n",
       "41     new blog 10 selfcare tip stayathome order frie...          100   \n",
       "92     column the column niece boyfriend need to read...          100   \n",
       "...                                                  ...          ...   \n",
       "16815  good friend amp hunt buddy need help midnight ...          100   \n",
       "16849  wife make mask true jane fashion make stylish ...          100   \n",
       "16860  james corden say he struggle incredible spike ...          100   \n",
       "16874  tonight mark big public endofquarter deadline ...          100   \n",
       "16894  rightwing evangelist jonathan shuttlesworth cl...          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "2                     end  \n",
       "10                    end  \n",
       "18                    end  \n",
       "41                    end  \n",
       "92                    end  \n",
       "...                   ...  \n",
       "16815                 end  \n",
       "16849                 end  \n",
       "16860             anxiety  \n",
       "16874                 end  \n",
       "16894                 end  \n",
       "\n",
       "[1031 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_ne.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06091580502215657\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
