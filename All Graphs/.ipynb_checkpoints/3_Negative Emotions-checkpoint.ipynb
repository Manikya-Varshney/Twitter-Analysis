{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/final_processed_data/final_processed_april10.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bored\n",
    "lonely\n",
    "stress\n",
    "anxiety\n",
    "scared\n",
    "worry\n",
    "end\n",
    "cabin fever\n",
    "#sideeffectsofquarantinelife\n",
    "tissue paper\n",
    "toilet paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['bored' , 'lonely', 'stress', \n",
    "            'anxiety', 'scared', 'worry', 'end', 'cabin fever',\n",
    "            '#sideeffectsofquarantinelife', 'tissue paper', 'toilet paper']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('‚Äú').strip('‚Äú').strip('‚Äô').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ne = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.879999e+09</td>\n",
       "      <td>@MeetThePress @chucktodd If Trump is doing suc...</td>\n",
       "      <td>trump great job the usa 30 the global covid19 ...</td>\n",
       "      <td>50</td>\n",
       "      <td>lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.631563e+09</td>\n",
       "      <td>@MyCielola, @FIOB_Oficial, @MayanLeague among ...</td>\n",
       "      <td>among indigenous organization denounce discrim...</td>\n",
       "      <td>67</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.175449e+08</td>\n",
       "      <td>It‚Äôs spring break and I‚Äôm supposed to be visit...</td>\n",
       "      <td>spring break  suppose to visit family tuscaloo...</td>\n",
       "      <td>75</td>\n",
       "      <td>bore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.003550e+09</td>\n",
       "      <td>One of my hardworking pharmacy techs fell ill ...</td>\n",
       "      <td>one hardworking pharmacy tech fell ill today c...</td>\n",
       "      <td>60</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.238635e+18</td>\n",
       "      <td>Looking for a quarantine boyfriend. Just text ...</td>\n",
       "      <td>look quarantine boyfriend text good morning go...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12993</th>\n",
       "      <td>3.821768e+08</td>\n",
       "      <td>Tonight‚Äôs virtual town hall with the RNS COVID...</td>\n",
       "      <td>tonight  virtual town hall the rn covid19 task...</td>\n",
       "      <td>50</td>\n",
       "      <td>lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12994</th>\n",
       "      <td>1.230608e+18</td>\n",
       "      <td>ICYMI: Commissioner @HodgenMainda is featured ...</td>\n",
       "      <td>icymi commissioner feature the new issue the t...</td>\n",
       "      <td>67</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12995</th>\n",
       "      <td>1.238883e+18</td>\n",
       "      <td>COVID Insurance Update 4/9/2020 https://t.co/j...</td>\n",
       "      <td>covid insurance update 492020 via</td>\n",
       "      <td>50</td>\n",
       "      <td>scar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12996</th>\n",
       "      <td>1.039776e+08</td>\n",
       "      <td>Good thing there are no rush hours these days....</td>\n",
       "      <td>good thing no rush hour day sq issue 1546 fine...</td>\n",
       "      <td>75</td>\n",
       "      <td>scar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997</th>\n",
       "      <td>7.506050e+07</td>\n",
       "      <td>Salud Para la Gente asked Leadership Award rec...</td>\n",
       "      <td>salud para la gente ask leadership award recip...</td>\n",
       "      <td>67</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12998 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "0      2.879999e+09  @MeetThePress @chucktodd If Trump is doing suc...   \n",
       "1      1.631563e+09  @MyCielola, @FIOB_Oficial, @MayanLeague among ...   \n",
       "2      4.175449e+08  It‚Äôs spring break and I‚Äôm supposed to be visit...   \n",
       "3      1.003550e+09  One of my hardworking pharmacy techs fell ill ...   \n",
       "4      1.238635e+18  Looking for a quarantine boyfriend. Just text ...   \n",
       "...             ...                                                ...   \n",
       "12993  3.821768e+08  Tonight‚Äôs virtual town hall with the RNS COVID...   \n",
       "12994  1.230608e+18  ICYMI: Commissioner @HodgenMainda is featured ...   \n",
       "12995  1.238883e+18  COVID Insurance Update 4/9/2020 https://t.co/j...   \n",
       "12996  1.039776e+08  Good thing there are no rush hours these days....   \n",
       "12997  7.506050e+07  Salud Para la Gente asked Leadership Award rec...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      trump great job the usa 30 the global covid19 ...           50   \n",
       "1      among indigenous organization denounce discrim...           67   \n",
       "2      spring break  suppose to visit family tuscaloo...           75   \n",
       "3      one hardworking pharmacy tech fell ill today c...           60   \n",
       "4      look quarantine boyfriend text good morning go...          100   \n",
       "...                                                  ...          ...   \n",
       "12993  tonight  virtual town hall the rn covid19 task...           50   \n",
       "12994  icymi commissioner feature the new issue the t...           67   \n",
       "12995                  covid insurance update 492020 via           50   \n",
       "12996  good thing no rush hour day sq issue 1546 fine...           75   \n",
       "12997  salud para la gente ask leadership award recip...           67   \n",
       "\n",
       "      final_keyword_match  \n",
       "0                  lonely  \n",
       "1                     end  \n",
       "2                    bore  \n",
       "3                   worry  \n",
       "4                     end  \n",
       "...                   ...  \n",
       "12993              lonely  \n",
       "12994                 end  \n",
       "12995                scar  \n",
       "12996                scar  \n",
       "12997                 end  \n",
       "\n",
       "[12998 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_ne.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ne['final_score'] = interim_ne['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ne = interim_ne[interim_ne['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.238635e+18</td>\n",
       "      <td>Looking for a quarantine boyfriend. Just text ...</td>\n",
       "      <td>look quarantine boyfriend text good morning go...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.504820e+17</td>\n",
       "      <td>These girls are taking a little Coronavirus br...</td>\n",
       "      <td>girl take little coronavirus break hit the res...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.907757e+07</td>\n",
       "      <td>I think I hit the #coronavirus jackpot. In jus...</td>\n",
       "      <td>think hit the coronavirus jackpot two trip man...</td>\n",
       "      <td>100</td>\n",
       "      <td>toilet paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.229759e+18</td>\n",
       "      <td>@TimNoEgo @FrakerMonica What Trump means is th...</td>\n",
       "      <td>trump mean grueling to stretch out watch quara...</td>\n",
       "      <td>100</td>\n",
       "      <td>cabin fever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.885170e+08</td>\n",
       "      <td>Time to curl up with that glass of wine üç∑ or t...</td>\n",
       "      <td>time to curl glass wine cup amp catch the late...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12860</th>\n",
       "      <td>3.173852e+08</td>\n",
       "      <td>@JoeBiden You‚Äôre right, we should send the ent...</td>\n",
       "      <td>right send the entire bill to china</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12865</th>\n",
       "      <td>3.160511e+06</td>\n",
       "      <td>Big formula companies told me they couldn‚Äôt he...</td>\n",
       "      <td>big formula company told  help u see  send new...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12878</th>\n",
       "      <td>8.364905e+07</td>\n",
       "      <td>Also: I deliberately left out Gwenpool, Dr. St...</td>\n",
       "      <td>also deliberately left out gwenpool dr strange...</td>\n",
       "      <td>100</td>\n",
       "      <td>scar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12964</th>\n",
       "      <td>2.427755e+07</td>\n",
       "      <td>JUST IN: 72% of AMERICANS say that they would ...</td>\n",
       "      <td>72 american say would attend game coronavirus ...</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12982</th>\n",
       "      <td>8.267539e+17</td>\n",
       "      <td>If your boyfriends kitchen is not like this.  ...</td>\n",
       "      <td>your boyfriend kitchen like somebody cleaning</td>\n",
       "      <td>100</td>\n",
       "      <td>end</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "4      1.238635e+18  Looking for a quarantine boyfriend. Just text ...   \n",
       "20     7.504820e+17  These girls are taking a little Coronavirus br...   \n",
       "22     1.907757e+07  I think I hit the #coronavirus jackpot. In jus...   \n",
       "24     1.229759e+18  @TimNoEgo @FrakerMonica What Trump means is th...   \n",
       "37     2.885170e+08  Time to curl up with that glass of wine üç∑ or t...   \n",
       "...             ...                                                ...   \n",
       "12860  3.173852e+08  @JoeBiden You‚Äôre right, we should send the ent...   \n",
       "12865  3.160511e+06  Big formula companies told me they couldn‚Äôt he...   \n",
       "12878  8.364905e+07  Also: I deliberately left out Gwenpool, Dr. St...   \n",
       "12964  2.427755e+07  JUST IN: 72% of AMERICANS say that they would ...   \n",
       "12982  8.267539e+17  If your boyfriends kitchen is not like this.  ...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "4      look quarantine boyfriend text good morning go...          100   \n",
       "20     girl take little coronavirus break hit the res...          100   \n",
       "22     think hit the coronavirus jackpot two trip man...          100   \n",
       "24     trump mean grueling to stretch out watch quara...          100   \n",
       "37     time to curl glass wine cup amp catch the late...          100   \n",
       "...                                                  ...          ...   \n",
       "12860                right send the entire bill to china          100   \n",
       "12865  big formula company told  help u see  send new...          100   \n",
       "12878  also deliberately left out gwenpool dr strange...          100   \n",
       "12964  72 american say would attend game coronavirus ...          100   \n",
       "12982      your boyfriend kitchen like somebody cleaning          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "4                     end  \n",
       "20                    end  \n",
       "22           toilet paper  \n",
       "24            cabin fever  \n",
       "37                    end  \n",
       "...                   ...  \n",
       "12860                 end  \n",
       "12865                 end  \n",
       "12878                scar  \n",
       "12964                 end  \n",
       "12982                 end  \n",
       "\n",
       "[810 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_ne.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.062317279581474073\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
