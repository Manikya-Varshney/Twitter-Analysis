{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/Test Data/final_processed_april01.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "silver lining\n",
    "optimistic\n",
    "hope\n",
    "bright side\n",
    "Safe\n",
    "#togetherapart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['silver lining' , 'optimistic', 'hope', \n",
    "            'bright side', 'Safe', '#togetherapart']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "data['final'].replace(\"\", nan_value, inplace=True)\n",
    "data.dropna(subset = [\"final\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '‍']\n"
     ]
    }
   ],
   "source": [
    "interim_pe = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.843399e+07</td>\n",
       "      <td>As Chicago households fill out 2020 census dur...</td>\n",
       "      <td>chicago household fill out 2020 census coronav...</td>\n",
       "      <td>50</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.010439e+08</td>\n",
       "      <td>Most of the press corps is very busy covering ...</td>\n",
       "      <td>the press corp busy cover the really important...</td>\n",
       "      <td>64</td>\n",
       "      <td>bright side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump Mar 10–he was very specific: ...</td>\n",
       "      <td>mar 10–he specific  google 1700 engineer work ...</td>\n",
       "      <td>55</td>\n",
       "      <td>bright side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.647527e+07</td>\n",
       "      <td>@realDonaldTrump , You were caustic &amp;amp; sarc...</td>\n",
       "      <td>caustic amp sarcastic the rollout  come even f...</td>\n",
       "      <td>50</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.453977e+08</td>\n",
       "      <td>Florida nears 8,000 coronavirus cases, as stat...</td>\n",
       "      <td>florida nears 8000 coronavirus case state repo...</td>\n",
       "      <td>54</td>\n",
       "      <td>togetherapart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16920</th>\n",
       "      <td>9.832288e+17</td>\n",
       "      <td>#SierraLeone has registered its index case of ...</td>\n",
       "      <td>sierraleone register index case covid19 from d...</td>\n",
       "      <td>64</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16921</th>\n",
       "      <td>1.856380e+07</td>\n",
       "      <td>KTAR News reporter @TaylorKinnerup gives a cor...</td>\n",
       "      <td>ktar news reporter give coronavirus update ari...</td>\n",
       "      <td>75</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16922</th>\n",
       "      <td>9.186279e+08</td>\n",
       "      <td>Part of a 1938 public health map: https://t.co...</td>\n",
       "      <td>part 1938 public health map</td>\n",
       "      <td>50</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16923</th>\n",
       "      <td>1.240031e+18</td>\n",
       "      <td>While the resourcefulness and hustle shown by ...</td>\n",
       "      <td>the resourcefulness hustle show many to produc...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16924</th>\n",
       "      <td>3.223426e+09</td>\n",
       "      <td>Six days ago, there were 13,355 new coronaviru...</td>\n",
       "      <td>six day ago 13355 new coronavirus case daily t...</td>\n",
       "      <td>50</td>\n",
       "      <td>optimistic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16925 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "0      2.843399e+07  As Chicago households fill out 2020 census dur...   \n",
       "1      1.010439e+08  Most of the press corps is very busy covering ...   \n",
       "2      1.647527e+07  @realDonaldTrump Mar 10–he was very specific: ...   \n",
       "3      1.647527e+07  @realDonaldTrump , You were caustic &amp; sarc...   \n",
       "4      3.453977e+08  Florida nears 8,000 coronavirus cases, as stat...   \n",
       "...             ...                                                ...   \n",
       "16920  9.832288e+17  #SierraLeone has registered its index case of ...   \n",
       "16921  1.856380e+07  KTAR News reporter @TaylorKinnerup gives a cor...   \n",
       "16922  9.186279e+08  Part of a 1938 public health map: https://t.co...   \n",
       "16923  1.240031e+18  While the resourcefulness and hustle shown by ...   \n",
       "16924  3.223426e+09  Six days ago, there were 13,355 new coronaviru...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      chicago household fill out 2020 census coronav...           50   \n",
       "1      the press corp busy cover the really important...           64   \n",
       "2      mar 10–he specific  google 1700 engineer work ...           55   \n",
       "3      caustic amp sarcastic the rollout  come even f...           50   \n",
       "4      florida nears 8000 coronavirus case state repo...           54   \n",
       "...                                                  ...          ...   \n",
       "16920  sierraleone register index case covid19 from d...           64   \n",
       "16921  ktar news reporter give coronavirus update ari...           75   \n",
       "16922                        part 1938 public health map           50   \n",
       "16923  the resourcefulness hustle show many to produc...           55   \n",
       "16924  six day ago 13355 new coronavirus case daily t...           50   \n",
       "\n",
       "      final_keyword_match  \n",
       "0                    safe  \n",
       "1             bright side  \n",
       "2             bright side  \n",
       "3                    hope  \n",
       "4           togetherapart  \n",
       "...                   ...  \n",
       "16920         silver line  \n",
       "16921                hope  \n",
       "16922                hope  \n",
       "16923         silver line  \n",
       "16924          optimistic  \n",
       "\n",
       "[16925 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_pe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_pe['final_score'] = interim_pe['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_pe = interim_pe[interim_pe['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.233541e+17</td>\n",
       "      <td>It is one thing to be optimistic or reassuring...</td>\n",
       "      <td>one thing to optimistic reassure entirely diff...</td>\n",
       "      <td>100</td>\n",
       "      <td>optimistic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.929292e+07</td>\n",
       "      <td>Happy #NationalPoetryMonth - new pandemic poet...</td>\n",
       "      <td>happy nationalpoetrymonth new pandemic poetry ...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>9.213913e+07</td>\n",
       "      <td>I hope you get Coronavirus</td>\n",
       "      <td>hope get coronavirus</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2.987983e+08</td>\n",
       "      <td>Yeah! #Nantucket\\nSTAY HOME SAFE LIVES\\nCenter...</td>\n",
       "      <td>yeah nantucket stay home safe life center dise...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>9.113652e+08</td>\n",
       "      <td>@Zigmanfreud We often miss mild cases of the f...</td>\n",
       "      <td>often miss mild case the flu well hope the fin...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>2.507388e+07</td>\n",
       "      <td>My proposal to the politically correct Automob...</td>\n",
       "      <td>proposal to the politically correct automobile...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16882</th>\n",
       "      <td>5.001266e+08</td>\n",
       "      <td>Revised: NEW INFORMATION. PLEASE READ CAREFULL...</td>\n",
       "      <td>revise new information please read carefully c...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>1.678039e+07</td>\n",
       "      <td>Stay Home. Stay Safe. Save Lives. The state of...</td>\n",
       "      <td>stay home stay safe save life the state michig...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16904</th>\n",
       "      <td>1.364865e+07</td>\n",
       "      <td>Had a rough day? Hopefully this will cheer you...</td>\n",
       "      <td>rough day hopefully cheer</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16918</th>\n",
       "      <td>3.690315e+08</td>\n",
       "      <td>We’re here for you. Please #StayHomeWorkSafe f...</td>\n",
       "      <td>please stayhomeworksafe u the late info covid1...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>602 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id                                     text_duplicate  \\\n",
       "13     8.233541e+17  It is one thing to be optimistic or reassuring...   \n",
       "26     2.929292e+07  Happy #NationalPoetryMonth - new pandemic poet...   \n",
       "32     9.213913e+07                         I hope you get Coronavirus   \n",
       "48     2.987983e+08  Yeah! #Nantucket\\nSTAY HOME SAFE LIVES\\nCenter...   \n",
       "52     9.113652e+08  @Zigmanfreud We often miss mild cases of the f...   \n",
       "...             ...                                                ...   \n",
       "16850  2.507388e+07  My proposal to the politically correct Automob...   \n",
       "16882  5.001266e+08  Revised: NEW INFORMATION. PLEASE READ CAREFULL...   \n",
       "16901  1.678039e+07  Stay Home. Stay Safe. Save Lives. The state of...   \n",
       "16904  1.364865e+07  Had a rough day? Hopefully this will cheer you...   \n",
       "16918  3.690315e+08  We’re here for you. Please #StayHomeWorkSafe f...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "13     one thing to optimistic reassure entirely diff...          100   \n",
       "26     happy nationalpoetrymonth new pandemic poetry ...          100   \n",
       "32                                  hope get coronavirus          100   \n",
       "48     yeah nantucket stay home safe life center dise...          100   \n",
       "52     often miss mild case the flu well hope the fin...          100   \n",
       "...                                                  ...          ...   \n",
       "16850  proposal to the politically correct automobile...          100   \n",
       "16882  revise new information please read carefully c...          100   \n",
       "16901  stay home stay safe save life the state michig...          100   \n",
       "16904                          rough day hopefully cheer          100   \n",
       "16918  please stayhomeworksafe u the late info covid1...          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "13             optimistic  \n",
       "26                   safe  \n",
       "32                   hope  \n",
       "48                   safe  \n",
       "52                   hope  \n",
       "...                   ...  \n",
       "16850                safe  \n",
       "16882                hope  \n",
       "16901                safe  \n",
       "16904                hope  \n",
       "16918                safe  \n",
       "\n",
       "[602 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_pe.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035568685376661746\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
