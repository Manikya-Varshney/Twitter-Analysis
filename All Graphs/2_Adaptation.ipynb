{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Graphs/final_processed_data/final_processed_april01.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "school from home\n",
    "learn\n",
    "remote\n",
    "school food service\n",
    "online shopping\n",
    "online purchase\n",
    "online church\n",
    "delivery\n",
    "drive thru\n",
    "to go\n",
    "take out\n",
    "Tiktok\n",
    "Netflix\n",
    "telework\n",
    "zoom\n",
    "telehealth\n",
    "telemedicine\n",
    "teleconference\n",
    "work from home\n",
    "wfh\n",
    "working at home\n",
    "working remotely\n",
    "online meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['school from home' , 'learn', 'remote', 'school food service', \n",
    "            'online shopping', 'online purchase', 'online church', 'delivery',\n",
    "            'drive thru', 'to go', 'take out', 'Tiktok', 'Netflix', 'telework', \n",
    "            'zoom', 'telehealth', 'telemedicine', 'work from home', 'wfh',\n",
    "            'working at home', 'working remotely', 'online meeting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('â€œ').strip('â€œ').strip('â€™').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28433993</td>\n",
       "      <td>As Chicago households fill out 2020 census dur...</td>\n",
       "      <td>chicago household fill out 2020 census coronav...</td>\n",
       "      <td>50</td>\n",
       "      <td>school from home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101043870</td>\n",
       "      <td>Most of the press corps is very busy covering ...</td>\n",
       "      <td>the press corp busy cover the really important...</td>\n",
       "      <td>75</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16475267</td>\n",
       "      <td>@realDonaldTrump Mar 10â€“he was very specific: ...</td>\n",
       "      <td>mar 10â€“he specific  google 1700 engineer work ...</td>\n",
       "      <td>75</td>\n",
       "      <td>telework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16475267</td>\n",
       "      <td>@realDonaldTrump , You were caustic &amp;amp; sarc...</td>\n",
       "      <td>caustic amp sarcastic the rollout  come even f...</td>\n",
       "      <td>60</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>345397708</td>\n",
       "      <td>Florida nears 8,000 coronavirus cases, as stat...</td>\n",
       "      <td>florida nears 8000 coronavirus case state repo...</td>\n",
       "      <td>62</td>\n",
       "      <td>telework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16185</th>\n",
       "      <td>751644712570847236</td>\n",
       "      <td>If in 1938 Turkeyâ€™s government could produce a...</td>\n",
       "      <td>1938 turkey  government could produce health m...</td>\n",
       "      <td>70</td>\n",
       "      <td>telehealth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16186</th>\n",
       "      <td>286628737</td>\n",
       "      <td>Sandy Medford was a friend of my family for de...</td>\n",
       "      <td>sandy medford friend family decade suspect hea...</td>\n",
       "      <td>60</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16187</th>\n",
       "      <td>361010205</td>\n",
       "      <td>One month ago Trump claimed the number of Amer...</td>\n",
       "      <td>one month ago trump claimed the number america...</td>\n",
       "      <td>60</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16188</th>\n",
       "      <td>481389842</td>\n",
       "      <td>Yes. This. Especially if a substantial proport...</td>\n",
       "      <td>yes especially substantial proportion workforc...</td>\n",
       "      <td>60</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16189</th>\n",
       "      <td>11347222</td>\n",
       "      <td>I'm sticking to my original lowball prediction...</td>\n",
       "      <td>im stick to original lowball prediction at lea...</td>\n",
       "      <td>80</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16190 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id                                     text_duplicate  \\\n",
       "0                28433993  As Chicago households fill out 2020 census dur...   \n",
       "1               101043870  Most of the press corps is very busy covering ...   \n",
       "2                16475267  @realDonaldTrump Mar 10â€“he was very specific: ...   \n",
       "3                16475267  @realDonaldTrump , You were caustic &amp; sarc...   \n",
       "4               345397708  Florida nears 8,000 coronavirus cases, as stat...   \n",
       "...                   ...                                                ...   \n",
       "16185  751644712570847236  If in 1938 Turkeyâ€™s government could produce a...   \n",
       "16186           286628737  Sandy Medford was a friend of my family for de...   \n",
       "16187           361010205  One month ago Trump claimed the number of Amer...   \n",
       "16188           481389842  Yes. This. Especially if a substantial proport...   \n",
       "16189            11347222  I'm sticking to my original lowball prediction...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "0      chicago household fill out 2020 census coronav...           50   \n",
       "1      the press corp busy cover the really important...           75   \n",
       "2      mar 10â€“he specific  google 1700 engineer work ...           75   \n",
       "3      caustic amp sarcastic the rollout  come even f...           60   \n",
       "4      florida nears 8000 coronavirus case state repo...           62   \n",
       "...                                                  ...          ...   \n",
       "16185  1938 turkey  government could produce health m...           70   \n",
       "16186  sandy medford friend family decade suspect hea...           60   \n",
       "16187  one month ago trump claimed the number america...           60   \n",
       "16188  yes especially substantial proportion workforc...           60   \n",
       "16189  im stick to original lowball prediction at lea...           80   \n",
       "\n",
       "      final_keyword_match  \n",
       "0        school from home  \n",
       "1                take out  \n",
       "2                telework  \n",
       "3                   to go  \n",
       "4                telework  \n",
       "...                   ...  \n",
       "16185          telehealth  \n",
       "16186               learn  \n",
       "16187               to go  \n",
       "16188               to go  \n",
       "16189               to go  \n",
       "\n",
       "[16190 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "denominator = interim_ada.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada['final_score'] = interim_ada['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada = interim_ada[interim_ada['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerator = interim_ada.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>859016395</td>\n",
       "      <td>A new normal for Congress:\\n- working from hom...</td>\n",
       "      <td>new normal congress work from home coronavirus...</td>\n",
       "      <td>100</td>\n",
       "      <td>work from home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1074530978</td>\n",
       "      <td>Hello Twitter, I have a rant. I work at Pizza ...</td>\n",
       "      <td>hello twitter rant work at pizza hut throughou...</td>\n",
       "      <td>100</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>232044555</td>\n",
       "      <td>A1 @a1softball schooling from home (Covid-19) ...</td>\n",
       "      <td>a1 school from home covid19 id auto shop 101 t...</td>\n",
       "      <td>100</td>\n",
       "      <td>school from home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>743183764130398208</td>\n",
       "      <td>Nothing has done more for a social media appli...</td>\n",
       "      <td>nothing do social medium application covid19 a...</td>\n",
       "      <td>100</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>256650910</td>\n",
       "      <td>Question ðŸ¤”: After this whole #coronavirus pand...</td>\n",
       "      <td>question whole coronavirus pandemic do think c...</td>\n",
       "      <td>100</td>\n",
       "      <td>work remotely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15867</th>\n",
       "      <td>1096052747315625984</td>\n",
       "      <td>Mar 2020:\\n-1st time sleeping in on a sat. w/ ...</td>\n",
       "      <td>mar 2020 1st time sleep sat w no obligation of...</td>\n",
       "      <td>100</td>\n",
       "      <td>remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15964</th>\n",
       "      <td>915288902</td>\n",
       "      <td>Be careful with your #Amazon orders! See my Fa...</td>\n",
       "      <td>careful your amazon order see facebook post cl...</td>\n",
       "      <td>100</td>\n",
       "      <td>delivery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16133</th>\n",
       "      <td>2849624090</td>\n",
       "      <td>Don't know why they're trying to blame this la...</td>\n",
       "      <td>dont know theyre try to blame lady cancel mard...</td>\n",
       "      <td>100</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16138</th>\n",
       "      <td>516835849</td>\n",
       "      <td>This Tik-Tok pandemic could be worse than COVI...</td>\n",
       "      <td>tiktok pandemic could bad covid</td>\n",
       "      <td>100</td>\n",
       "      <td>tiktok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16165</th>\n",
       "      <td>119260499</td>\n",
       "      <td>Really good show today. Learned about COVID-19...</td>\n",
       "      <td>really good show today learn covid19 the resea...</td>\n",
       "      <td>100</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id                                     text_duplicate  \\\n",
       "38               859016395  A new normal for Congress:\\n- working from hom...   \n",
       "77              1074530978  Hello Twitter, I have a rant. I work at Pizza ...   \n",
       "92               232044555  A1 @a1softball schooling from home (Covid-19) ...   \n",
       "101     743183764130398208  Nothing has done more for a social media appli...   \n",
       "102              256650910  Question ðŸ¤”: After this whole #coronavirus pand...   \n",
       "...                    ...                                                ...   \n",
       "15867  1096052747315625984  Mar 2020:\\n-1st time sleeping in on a sat. w/ ...   \n",
       "15964            915288902  Be careful with your #Amazon orders! See my Fa...   \n",
       "16133           2849624090  Don't know why they're trying to blame this la...   \n",
       "16138            516835849  This Tik-Tok pandemic could be worse than COVI...   \n",
       "16165            119260499  Really good show today. Learned about COVID-19...   \n",
       "\n",
       "                                                   final  final_score  \\\n",
       "38     new normal congress work from home coronavirus...          100   \n",
       "77     hello twitter rant work at pizza hut throughou...          100   \n",
       "92     a1 school from home covid19 id auto shop 101 t...          100   \n",
       "101    nothing do social medium application covid19 a...          100   \n",
       "102    question whole coronavirus pandemic do think c...          100   \n",
       "...                                                  ...          ...   \n",
       "15867  mar 2020 1st time sleep sat w no obligation of...          100   \n",
       "15964  careful your amazon order see facebook post cl...          100   \n",
       "16133  dont know theyre try to blame lady cancel mard...          100   \n",
       "16138                    tiktok pandemic could bad covid          100   \n",
       "16165  really good show today learn covid19 the resea...          100   \n",
       "\n",
       "      final_keyword_match  \n",
       "38         work from home  \n",
       "77               delivery  \n",
       "92       school from home  \n",
       "101                tiktok  \n",
       "102         work remotely  \n",
       "...                   ...  \n",
       "15867              remote  \n",
       "15964            delivery  \n",
       "16133               learn  \n",
       "16138              tiktok  \n",
       "16165               learn  \n",
       "\n",
       "[495 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03057442865966646\n"
     ]
    }
   ],
   "source": [
    "proportion = (numerator/denominator)\n",
    "print(proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
