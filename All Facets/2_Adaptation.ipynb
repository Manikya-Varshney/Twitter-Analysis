{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/final_processed_h01-20200912-101538.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "school from home\n",
    "learn\n",
    "remote\n",
    "school food service\n",
    "online shopping\n",
    "online purchase\n",
    "online church\n",
    "delivery\n",
    "drive thru\n",
    "to go\n",
    "take out\n",
    "Tiktok\n",
    "Netflix\n",
    "telework\n",
    "zoom\n",
    "telehealth\n",
    "telemedicine\n",
    "teleconference\n",
    "work from home\n",
    "wfh\n",
    "working at home\n",
    "working remotely\n",
    "online meeting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['school from home' , 'learn', 'remote', 'school food service', \n",
    "            'online shopping', 'online purchase', 'online church', 'delivery',\n",
    "            'drive thru', 'to go', 'take out', 'Tiktok', 'Netflix', 'telework', \n",
    "            'zoom', 'telehealth', 'telemedicine', 'work from home', 'wfh',\n",
    "            'working at home', 'working remotely', 'online meeting']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fuzzy_m(row):\n",
    "    matches = process.extract(row['final'], keywords_final, limit=3)\n",
    "    exactMatch = matches[0][1] == 90\n",
    "    row['Match 1'] = matches[0][0]\n",
    "    row['Match 1 Score'] = matches[0][1]\n",
    "    row['Match 2'] = \"\" if exactMatch else matches[1][0]\n",
    "    row['Match 2 Score'] = \"\" if exactMatch else matches[1][1]\n",
    "    row['Match 3'] = \"\" if exactMatch else matches[2][0]\n",
    "    row['Match 3 Score'] = \"\" if exactMatch else matches[2][1]\n",
    "    return row    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "interim_ada = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_ada"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_ada['Match 1 Score'] = interim_ada['Match 1 Score'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_ada[interim['Match 1 Score'] == 90].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.053900e+07</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke to see the justin bieber pandemic go back...</td>\n",
       "      <td>62</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.497239e+17</td>\n",
       "      <td>our intention is to make sure that evidence sc...</td>\n",
       "      <td>@TeresaCCarter2 “Our intention is to make sure...</td>\n",
       "      <td>intention to make sure evidence sciencebased ...</td>\n",
       "      <td>62</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.293830e+18</td>\n",
       "      <td>for more information contact us  mail  follow ...</td>\n",
       "      <td>For More Information contact us. \\nMail:- digi...</td>\n",
       "      <td>information contact u mail follow instagram gy...</td>\n",
       "      <td>60</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.188902e+18</td>\n",
       "      <td>uae reports 1007 new covid19 cases highest sin...</td>\n",
       "      <td>UAE reports 1,007 new Covid-19 cases, highest ...</td>\n",
       "      <td>uae report 1007 new covid19 case high since ou...</td>\n",
       "      <td>67</td>\n",
       "      <td>remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.273830e+08</td>\n",
       "      <td>trump officials interfered with cdc reports on...</td>\n",
       "      <td>Trump officials interfered with CDC reports on...</td>\n",
       "      <td>trump official interfere cdc report covid19 po...</td>\n",
       "      <td>50</td>\n",
       "      <td>remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1.304427e+18</td>\n",
       "      <td>6.874206e+07</td>\n",
       "      <td>why did twitter suddenly reinstate   could it ...</td>\n",
       "      <td>Why did Twitter suddenly reinstate @clif_high?...</td>\n",
       "      <td>twitter suddenly reinstate could science valid...</td>\n",
       "      <td>75</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>1.304671e+18</td>\n",
       "      <td>8.323244e+17</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>Denna veckas COVID-19 veckorapport från Folkhä...</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>50</td>\n",
       "      <td>remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>4.446656e+09</td>\n",
       "      <td>republicans defend trump after he admitted dow...</td>\n",
       "      <td>Republicans Defend Trump After He Admitted Dow...</td>\n",
       "      <td>republican defend trump admit downplay true th...</td>\n",
       "      <td>60</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>1.301853e+18</td>\n",
       "      <td>3.914277e+08</td>\n",
       "      <td>the recession on the back of the governments h...</td>\n",
       "      <td>The recession on the back of the Government's ...</td>\n",
       "      <td>the recession the back the government handle c...</td>\n",
       "      <td>67</td>\n",
       "      <td>wfh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1.304756e+18</td>\n",
       "      <td>2.215891e+09</td>\n",
       "      <td>65 catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 Catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 catholic across the street 7 wear mask</td>\n",
       "      <td>60</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "0     1.304786e+18  9.053900e+07   \n",
       "1     1.304786e+18  8.497239e+17   \n",
       "2     1.304786e+18  1.293830e+18   \n",
       "3     1.304786e+18  1.188902e+18   \n",
       "4     1.304786e+18  2.273830e+08   \n",
       "...            ...           ...   \n",
       "6732  1.304427e+18  6.874206e+07   \n",
       "6733  1.304671e+18  8.323244e+17   \n",
       "6734  1.304768e+18  4.446656e+09   \n",
       "6735  1.301853e+18  3.914277e+08   \n",
       "6736  1.304756e+18  2.215891e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     our intention is to make sure that evidence sc...   \n",
       "2     for more information contact us  mail  follow ...   \n",
       "3     uae reports 1007 new covid19 cases highest sin...   \n",
       "4     trump officials interfered with cdc reports on...   \n",
       "...                                                 ...   \n",
       "6732  why did twitter suddenly reinstate   could it ...   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...   \n",
       "6734  republicans defend trump after he admitted dow...   \n",
       "6735  the recession on the back of the governments h...   \n",
       "6736  65 catholics across the street only 7 wearing ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     @TeresaCCarter2 “Our intention is to make sure...   \n",
       "2     For More Information contact us. \\nMail:- digi...   \n",
       "3     UAE reports 1,007 new Covid-19 cases, highest ...   \n",
       "4     Trump officials interfered with CDC reports on...   \n",
       "...                                                 ...   \n",
       "6732  Why did Twitter suddenly reinstate @clif_high?...   \n",
       "6733  Denna veckas COVID-19 veckorapport från Folkhä...   \n",
       "6734  Republicans Defend Trump After He Admitted Dow...   \n",
       "6735  The recession on the back of the Government's ...   \n",
       "6736  65 Catholics across the street only 7 wearing ...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "0     woke to see the justin bieber pandemic go back...           62   \n",
       "1      intention to make sure evidence sciencebased ...           62   \n",
       "2     information contact u mail follow instagram gy...           60   \n",
       "3     uae report 1007 new covid19 case high since ou...           67   \n",
       "4     trump official interfere cdc report covid19 po...           50   \n",
       "...                                                 ...          ...   \n",
       "6732  twitter suddenly reinstate could science valid...           75   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...           50   \n",
       "6734  republican defend trump admit downplay true th...           60   \n",
       "6735  the recession the back the government handle c...           67   \n",
       "6736          65 catholic across the street 7 wear mask           60   \n",
       "\n",
       "     final_keyword_match  \n",
       "0               take out  \n",
       "1               take out  \n",
       "2                  to go  \n",
       "3                 remote  \n",
       "4                 remote  \n",
       "...                  ...  \n",
       "6732            take out  \n",
       "6733              remote  \n",
       "6734               learn  \n",
       "6735                 wfh  \n",
       "6736               learn  \n",
       "\n",
       "[6737 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada['final_score'] = interim_ada['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.296229e+18</td>\n",
       "      <td>truthfully i took it out earlier in quarantine...</td>\n",
       "      <td>truthfully I took it out earlier in quarantine...</td>\n",
       "      <td>truthfully take out earlier quarantine  consid...</td>\n",
       "      <td>100</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.494314e+09</td>\n",
       "      <td>please be kind to teachers in the next few wee...</td>\n",
       "      <td>Please be kind to teachers in the next few wee...</td>\n",
       "      <td>please kind to teacher the next week teacher t...</td>\n",
       "      <td>100</td>\n",
       "      <td>remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.061882e+18</td>\n",
       "      <td>closing next week had to move out for a few da...</td>\n",
       "      <td>Closing next week, had to move out for a few d...</td>\n",
       "      <td>closing next week to move out day order quiet ...</td>\n",
       "      <td>100</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.289752e+17</td>\n",
       "      <td>due to the pandemic children are not going out...</td>\n",
       "      <td>@ScottPresler @MaryMargOlohan Due to the pande...</td>\n",
       "      <td>due to the pandemic child go outside pedophile...</td>\n",
       "      <td>100</td>\n",
       "      <td>netflix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>3.015735e+08</td>\n",
       "      <td>i doubt it up here anyway there has been plent...</td>\n",
       "      <td>@hired_merc I doubt it, up here anyway. There ...</td>\n",
       "      <td>doubt anyway plenty player test positive take ...</td>\n",
       "      <td>100</td>\n",
       "      <td>take out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6470</th>\n",
       "      <td>1.293707e+18</td>\n",
       "      <td>2.649893e+09</td>\n",
       "      <td>just learned my grandma has covid and is being...</td>\n",
       "      <td>Just learned my grandma has COVID and is being...</td>\n",
       "      <td>learn grandma covid transfer out assist care c...</td>\n",
       "      <td>100</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>1.304736e+18</td>\n",
       "      <td>9.888590e+08</td>\n",
       "      <td>first ever zoom meeting of  with their beloved...</td>\n",
       "      <td>First ever zoom meeting of @AAPMumbai with the...</td>\n",
       "      <td>first ever zoom meeting beloved leader say aap...</td>\n",
       "      <td>100</td>\n",
       "      <td>zoom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6637</th>\n",
       "      <td>1.304362e+18</td>\n",
       "      <td>2.507388e+07</td>\n",
       "      <td>congratulations to jpmorgan chase for ordering...</td>\n",
       "      <td>Congratulations to JPMorgan Chase for ordering...</td>\n",
       "      <td>congratulation to jpmorgan chase order everyon...</td>\n",
       "      <td>100</td>\n",
       "      <td>work from home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6719</th>\n",
       "      <td>1.235309e+18</td>\n",
       "      <td>8.189486e+17</td>\n",
       "      <td>reviewing the coronavirus supplemental appropr...</td>\n",
       "      <td>Reviewing the coronavirus supplemental appropr...</td>\n",
       "      <td>review the coronavirus supplemental appropriat...</td>\n",
       "      <td>100</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6725</th>\n",
       "      <td>1.304739e+18</td>\n",
       "      <td>1.295046e+18</td>\n",
       "      <td>quiet update to govt schools guidance schools ...</td>\n",
       "      <td>Quiet update to Govt schools guidance schools ...</td>\n",
       "      <td>quiet update to govt school guidance school re...</td>\n",
       "      <td>100</td>\n",
       "      <td>to go</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "33    1.304786e+18  1.296229e+18   \n",
       "47    1.304786e+18  1.494314e+09   \n",
       "70    1.304786e+18  1.061882e+18   \n",
       "71    1.304786e+18  8.289752e+17   \n",
       "110   1.304786e+18  3.015735e+08   \n",
       "...            ...           ...   \n",
       "6470  1.293707e+18  2.649893e+09   \n",
       "6493  1.304736e+18  9.888590e+08   \n",
       "6637  1.304362e+18  2.507388e+07   \n",
       "6719  1.235309e+18  8.189486e+17   \n",
       "6725  1.304739e+18  1.295046e+18   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "33    truthfully i took it out earlier in quarantine...   \n",
       "47    please be kind to teachers in the next few wee...   \n",
       "70    closing next week had to move out for a few da...   \n",
       "71    due to the pandemic children are not going out...   \n",
       "110   i doubt it up here anyway there has been plent...   \n",
       "...                                                 ...   \n",
       "6470  just learned my grandma has covid and is being...   \n",
       "6493  first ever zoom meeting of  with their beloved...   \n",
       "6637  congratulations to jpmorgan chase for ordering...   \n",
       "6719  reviewing the coronavirus supplemental appropr...   \n",
       "6725  quiet update to govt schools guidance schools ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "33    truthfully I took it out earlier in quarantine...   \n",
       "47    Please be kind to teachers in the next few wee...   \n",
       "70    Closing next week, had to move out for a few d...   \n",
       "71    @ScottPresler @MaryMargOlohan Due to the pande...   \n",
       "110   @hired_merc I doubt it, up here anyway. There ...   \n",
       "...                                                 ...   \n",
       "6470  Just learned my grandma has COVID and is being...   \n",
       "6493  First ever zoom meeting of @AAPMumbai with the...   \n",
       "6637  Congratulations to JPMorgan Chase for ordering...   \n",
       "6719  Reviewing the coronavirus supplemental appropr...   \n",
       "6725  Quiet update to Govt schools guidance schools ...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "33    truthfully take out earlier quarantine  consid...          100   \n",
       "47    please kind to teacher the next week teacher t...          100   \n",
       "70    closing next week to move out day order quiet ...          100   \n",
       "71    due to the pandemic child go outside pedophile...          100   \n",
       "110   doubt anyway plenty player test positive take ...          100   \n",
       "...                                                 ...          ...   \n",
       "6470  learn grandma covid transfer out assist care c...          100   \n",
       "6493  first ever zoom meeting beloved leader say aap...          100   \n",
       "6637  congratulation to jpmorgan chase order everyon...          100   \n",
       "6719  review the coronavirus supplemental appropriat...          100   \n",
       "6725  quiet update to govt school guidance school re...          100   \n",
       "\n",
       "     final_keyword_match  \n",
       "33              take out  \n",
       "47                remote  \n",
       "70                  zoom  \n",
       "71               netflix  \n",
       "110             take out  \n",
       "...                  ...  \n",
       "6470               learn  \n",
       "6493                zoom  \n",
       "6637      work from home  \n",
       "6719               to go  \n",
       "6725               to go  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_ada[interim_ada['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_ada[interim_ada['final_score'] == 100].to_csv('interim_ada.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "b = [\"online church\", \"lockdown\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = [\"church online\", \"lockdown\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = \"looking forward to worshipping together online family tomorrow as we start our new sermon series on ‘mission shaped living’ sundaysonline missionshapedliving worship birminghamlockdown covid19 stayalertsavelives\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "process.extract(a, b, scorer = fuzz.partial_ratio)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "process.extract(a, c, scorer = fuzz.partial_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
