{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Facets/final(Analysis)_h01-20200912-101538.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "social functions\n",
    "gathering\n",
    "empty streets\n",
    "interaction\n",
    "large\n",
    "no cars\n",
    "non-essential\n",
    "travel\n",
    "unnecessary\n",
    "crowd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['social functions' , 'gathering', 'empty streets', \n",
    "            'interaction', 'large', 'no cars', 'non-essential',\n",
    "            'travel', 'unnecessary', 'crowd',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.053900e+07</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke to see the justin bieber pandemic go back...</td>\n",
       "      <td>50</td>\n",
       "      <td>no car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.497239e+17</td>\n",
       "      <td>our intention is to make sure that evidence sc...</td>\n",
       "      <td>@TeresaCCarter2 “Our intention is to make sure...</td>\n",
       "      <td>intention to make sure evidence sciencebased ...</td>\n",
       "      <td>73</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.293830e+18</td>\n",
       "      <td>for more information contact us  mail  follow ...</td>\n",
       "      <td>For More Information contact us. \\nMail:- digi...</td>\n",
       "      <td>information contact u mail follow instagram gy...</td>\n",
       "      <td>73</td>\n",
       "      <td>interaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.188902e+18</td>\n",
       "      <td>uae reports 1007 new covid19 cases highest sin...</td>\n",
       "      <td>UAE reports 1,007 new Covid-19 cases, highest ...</td>\n",
       "      <td>uae report 1007 new covid19 case high since ou...</td>\n",
       "      <td>60</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.273830e+08</td>\n",
       "      <td>trump officials interfered with cdc reports on...</td>\n",
       "      <td>Trump officials interfered with CDC reports on...</td>\n",
       "      <td>trump official interfere cdc report covid19 po...</td>\n",
       "      <td>60</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1.304427e+18</td>\n",
       "      <td>6.874206e+07</td>\n",
       "      <td>why did twitter suddenly reinstate   could it ...</td>\n",
       "      <td>Why did Twitter suddenly reinstate @clif_high?...</td>\n",
       "      <td>twitter suddenly reinstate could science valid...</td>\n",
       "      <td>67</td>\n",
       "      <td>no car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>1.304671e+18</td>\n",
       "      <td>8.323244e+17</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>Denna veckas COVID-19 veckorapport från Folkhä...</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>58</td>\n",
       "      <td>nonessential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>4.446656e+09</td>\n",
       "      <td>republicans defend trump after he admitted dow...</td>\n",
       "      <td>Republicans Defend Trump After He Admitted Dow...</td>\n",
       "      <td>republican defend trump admit downplay true th...</td>\n",
       "      <td>60</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>1.301853e+18</td>\n",
       "      <td>3.914277e+08</td>\n",
       "      <td>the recession on the back of the governments h...</td>\n",
       "      <td>The recession on the back of the Government's ...</td>\n",
       "      <td>the recession the back the government handle c...</td>\n",
       "      <td>56</td>\n",
       "      <td>gathering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1.304756e+18</td>\n",
       "      <td>2.215891e+09</td>\n",
       "      <td>65 catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 Catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 catholic across the street 7 wear mask</td>\n",
       "      <td>67</td>\n",
       "      <td>empty street</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "0     1.304786e+18  9.053900e+07   \n",
       "1     1.304786e+18  8.497239e+17   \n",
       "2     1.304786e+18  1.293830e+18   \n",
       "3     1.304786e+18  1.188902e+18   \n",
       "4     1.304786e+18  2.273830e+08   \n",
       "...            ...           ...   \n",
       "6732  1.304427e+18  6.874206e+07   \n",
       "6733  1.304671e+18  8.323244e+17   \n",
       "6734  1.304768e+18  4.446656e+09   \n",
       "6735  1.301853e+18  3.914277e+08   \n",
       "6736  1.304756e+18  2.215891e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     our intention is to make sure that evidence sc...   \n",
       "2     for more information contact us  mail  follow ...   \n",
       "3     uae reports 1007 new covid19 cases highest sin...   \n",
       "4     trump officials interfered with cdc reports on...   \n",
       "...                                                 ...   \n",
       "6732  why did twitter suddenly reinstate   could it ...   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...   \n",
       "6734  republicans defend trump after he admitted dow...   \n",
       "6735  the recession on the back of the governments h...   \n",
       "6736  65 catholics across the street only 7 wearing ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     @TeresaCCarter2 “Our intention is to make sure...   \n",
       "2     For More Information contact us. \\nMail:- digi...   \n",
       "3     UAE reports 1,007 new Covid-19 cases, highest ...   \n",
       "4     Trump officials interfered with CDC reports on...   \n",
       "...                                                 ...   \n",
       "6732  Why did Twitter suddenly reinstate @clif_high?...   \n",
       "6733  Denna veckas COVID-19 veckorapport från Folkhä...   \n",
       "6734  Republicans Defend Trump After He Admitted Dow...   \n",
       "6735  The recession on the back of the Government's ...   \n",
       "6736  65 Catholics across the street only 7 wearing ...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "0     woke to see the justin bieber pandemic go back...           50   \n",
       "1      intention to make sure evidence sciencebased ...           73   \n",
       "2     information contact u mail follow instagram gy...           73   \n",
       "3     uae report 1007 new covid19 case high since ou...           60   \n",
       "4     trump official interfere cdc report covid19 po...           60   \n",
       "...                                                 ...          ...   \n",
       "6732  twitter suddenly reinstate could science valid...           67   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...           58   \n",
       "6734  republican defend trump admit downplay true th...           60   \n",
       "6735  the recession the back the government handle c...           56   \n",
       "6736          65 catholic across the street 7 wear mask           67   \n",
       "\n",
       "     final_keyword_match  \n",
       "0                 no car  \n",
       "1            interaction  \n",
       "2            interaction  \n",
       "3                  crowd  \n",
       "4                  crowd  \n",
       "...                  ...  \n",
       "6732              no car  \n",
       "6733        nonessential  \n",
       "6734               crowd  \n",
       "6735           gathering  \n",
       "6736        empty street  \n",
       "\n",
       "[6737 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd['final_score'] = interim_sd['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.251557e+08</td>\n",
       "      <td>the data generated so far are mostly individua...</td>\n",
       "      <td>@HardMoneyCowboy @SteveSkojec @MarkBra32931299...</td>\n",
       "      <td>the data generate far mostly individual case s...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.262011e+09</td>\n",
       "      <td>this is pelosi and others inviting people to c...</td>\n",
       "      <td>https://t.co/eqhxBOMMnn\\nTHIS IS PELOSI AND OT...</td>\n",
       "      <td>pelosi others invite people to china town play...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.149197e+18</td>\n",
       "      <td>i had an argument and didnt allow a family fri...</td>\n",
       "      <td>I had an argument and didn't allow a family fr...</td>\n",
       "      <td>argument didnt allow family friend army office...</td>\n",
       "      <td>100</td>\n",
       "      <td>unnecessary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>3.152371e+09</td>\n",
       "      <td>strictly come dancing cancel blackpool special...</td>\n",
       "      <td>Strictly Come Dancing CANCEL Blackpool special...</td>\n",
       "      <td>strictly come dance cancel blackpool special d...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>3.527413e+08</td>\n",
       "      <td>i get the reasoning though reducing travel off...</td>\n",
       "      <td>@mindsetssb I get the reasoning though, reduci...</td>\n",
       "      <td>get the reason though reduce travel campus red...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6442</th>\n",
       "      <td>1.304171e+18</td>\n",
       "      <td>2.277196e+07</td>\n",
       "      <td>very little social distancing and not many mas...</td>\n",
       "      <td>Very little social distancing and not many mas...</td>\n",
       "      <td>little social distance many mask inside crowd ...</td>\n",
       "      <td>100</td>\n",
       "      <td>crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6444</th>\n",
       "      <td>1.304082e+18</td>\n",
       "      <td>2.601485e+08</td>\n",
       "      <td>you want outsiders like me to come back to del...</td>\n",
       "      <td>@GGSIPUIndia you want outsiders like me to com...</td>\n",
       "      <td>want outsider like to come back to delhi time ...</td>\n",
       "      <td>100</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>1.304428e+18</td>\n",
       "      <td>5.671716e+08</td>\n",
       "      <td>do not travel to porthcawl in large numbers ov...</td>\n",
       "      <td>Do not travel to #Porthcawl in large numbers o...</td>\n",
       "      <td>do travel to porthcawl large number the weeken...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>1.221882e+18</td>\n",
       "      <td>2.361712e+09</td>\n",
       "      <td>large boulder the size of a small boulder is c...</td>\n",
       "      <td>Large boulder the size of a small boulder is c...</td>\n",
       "      <td>large boulder the size small boulder completel...</td>\n",
       "      <td>100</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6682</th>\n",
       "      <td>1.303462e+18</td>\n",
       "      <td>3.554202e+09</td>\n",
       "      <td>corona when it sees a large gathering but then...</td>\n",
       "      <td>Corona when it sees a large gathering but then...</td>\n",
       "      <td>corona see large gathering realises  work scho...</td>\n",
       "      <td>100</td>\n",
       "      <td>gathering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "48    1.304786e+18  8.251557e+08   \n",
       "92    1.304786e+18  2.262011e+09   \n",
       "198   1.304786e+18  1.149197e+18   \n",
       "203   1.304786e+18  3.152371e+09   \n",
       "269   1.304786e+18  3.527413e+08   \n",
       "...            ...           ...   \n",
       "6442  1.304171e+18  2.277196e+07   \n",
       "6444  1.304082e+18  2.601485e+08   \n",
       "6503  1.304428e+18  5.671716e+08   \n",
       "6572  1.221882e+18  2.361712e+09   \n",
       "6682  1.303462e+18  3.554202e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "48    the data generated so far are mostly individua...   \n",
       "92    this is pelosi and others inviting people to c...   \n",
       "198   i had an argument and didnt allow a family fri...   \n",
       "203   strictly come dancing cancel blackpool special...   \n",
       "269   i get the reasoning though reducing travel off...   \n",
       "...                                                 ...   \n",
       "6442  very little social distancing and not many mas...   \n",
       "6444  you want outsiders like me to come back to del...   \n",
       "6503  do not travel to porthcawl in large numbers ov...   \n",
       "6572  large boulder the size of a small boulder is c...   \n",
       "6682  corona when it sees a large gathering but then...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "48    @HardMoneyCowboy @SteveSkojec @MarkBra32931299...   \n",
       "92    https://t.co/eqhxBOMMnn\\nTHIS IS PELOSI AND OT...   \n",
       "198   I had an argument and didn't allow a family fr...   \n",
       "203   Strictly Come Dancing CANCEL Blackpool special...   \n",
       "269   @mindsetssb I get the reasoning though, reduci...   \n",
       "...                                                 ...   \n",
       "6442  Very little social distancing and not many mas...   \n",
       "6444  @GGSIPUIndia you want outsiders like me to com...   \n",
       "6503  Do not travel to #Porthcawl in large numbers o...   \n",
       "6572  Large boulder the size of a small boulder is c...   \n",
       "6682  Corona when it sees a large gathering but then...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "48    the data generate far mostly individual case s...          100   \n",
       "92    pelosi others invite people to china town play...          100   \n",
       "198   argument didnt allow family friend army office...          100   \n",
       "203   strictly come dance cancel blackpool special d...          100   \n",
       "269   get the reason though reduce travel campus red...          100   \n",
       "...                                                 ...          ...   \n",
       "6442  little social distance many mask inside crowd ...          100   \n",
       "6444  want outsider like to come back to delhi time ...          100   \n",
       "6503  do travel to porthcawl large number the weeken...          100   \n",
       "6572  large boulder the size small boulder completel...          100   \n",
       "6682  corona see large gathering realises  work scho...          100   \n",
       "\n",
       "     final_keyword_match  \n",
       "48                 large  \n",
       "92                travel  \n",
       "198          unnecessary  \n",
       "203               travel  \n",
       "269               travel  \n",
       "...                  ...  \n",
       "6442               crowd  \n",
       "6444              travel  \n",
       "6503               large  \n",
       "6572               large  \n",
       "6682           gathering  \n",
       "\n",
       "[106 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_sd[interim_sd['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_sd[interim_sd['final_score'] == 100].to_csv('interim_sd.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
