{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U python-Levenshtein"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "!{sys.executable} -m pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/manikya_varshney/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag, pos_tag_sents\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')) - set(['at', 'do', 'your', 'from', 'to', 'out', 'no', 'the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/manikya_varshney/Documents/Python/Yale/All Facets/final(Analysis)_h01-20200912-101538.csv'\n",
    "data = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "silver lining\n",
    "optimistic\n",
    "hope\n",
    "bright side\n",
    "Safe\n",
    "#togetherapart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['silver lining' , 'optimistic', 'hope', \n",
    "            'bright side', 'Safe', '#togetherapart']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Casing (Upper or lower case)\n",
    "##### 2. Noise Removal (Removal of punctuation, white spaces, special characters, HTML tags)\n",
    "##### 3. Tokenization (Tweets to tokens i.e. words seprated by spaces)\n",
    "##### 4. Stopword Removal\n",
    "##### 5. Text Normalization (Stemming and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to lower\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].lower()\n",
    "\n",
    "#Remove punctuations   \n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#More cleaning\n",
    "for i in range(len(keywords)): \n",
    "    keywords[i] = keywords[i].replace('/[^a-zA-Z0-9 ]/g', '').replace('\\n',' ').strip('“').strip('“').strip('’').lstrip(' ').rstrip(' ')\n",
    "\n",
    "#Tokenize\n",
    "#keywords_tokens = [sub.split() for sub in keywords] \n",
    "\n",
    "#Remove stop words\n",
    "def remove_stopwords(data):\n",
    "    output_array=[]\n",
    "    for sentence in data:\n",
    "        temp_list=[]\n",
    "        for word in sentence.split():\n",
    "            if word not in stop_words:\n",
    "                temp_list.append(word)\n",
    "        output_array.append(' '.join(temp_list))\n",
    "    return output_array\n",
    "\n",
    "keywords_filtered=remove_stopwords(keywords)\n",
    "\n",
    "#Stemming\n",
    "ps = PorterStemmer()\n",
    "keywords_stem = [[ps.stem(word) for word in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_stem = [\" \".join(sentence) for sentence in keywords_stem]\n",
    "\n",
    "#Lemmetizing\n",
    "\n",
    "#POSTags\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "keywords_lem = [[lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in sentence.split(\" \")] for sentence in keywords_filtered]\n",
    "keywords_final = [\" \".join(sentence) for sentence in keywords_lem]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['final'] = data['final'].apply(str)\n",
    "choices = data['final'].tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def fuzzy_m(row):\n",
    "    matches = process.extract(row['final'], keywords_final, limit=3)\n",
    "    exactMatch = matches[0][1] == 90\n",
    "    row['Match 1'] = matches[0][0]\n",
    "    row['Match 1 Score'] = matches[0][1]\n",
    "    row['Match 2'] = \"\" if exactMatch else matches[1][0]\n",
    "    row['Match 2 Score'] = \"\" if exactMatch else matches[1][1]\n",
    "    row['Match 3'] = \"\" if exactMatch else matches[2][0]\n",
    "    row['Match 3 Score'] = \"\" if exactMatch else matches[2][1]\n",
    "    return row    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "interim_pe = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_pe"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_pe['Match 1 Score'] = interim_pe['Match 1 Score'].astype(int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "interim_pe[interim_pe['Match 1 Score'] == 90].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " def fuzzy_m(row):\n",
    "        keyword_match, score = process.extractOne(row['final'], keywords_final, scorer = fuzz.partial_ratio)\n",
    "        row['final_score'] = score\n",
    "        row['final_keyword_match'] = keyword_match\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_pe = data.apply(fuzzy_m, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>9.053900e+07</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke up to see if the justin bieber pandemic w...</td>\n",
       "      <td>woke to see the justin bieber pandemic go back...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>8.497239e+17</td>\n",
       "      <td>our intention is to make sure that evidence sc...</td>\n",
       "      <td>@TeresaCCarter2 “Our intention is to make sure...</td>\n",
       "      <td>intention to make sure evidence sciencebased ...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.293830e+18</td>\n",
       "      <td>for more information contact us  mail  follow ...</td>\n",
       "      <td>For More Information contact us. \\nMail:- digi...</td>\n",
       "      <td>information contact u mail follow instagram gy...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.188902e+18</td>\n",
       "      <td>uae reports 1007 new covid19 cases highest sin...</td>\n",
       "      <td>UAE reports 1,007 new Covid-19 cases, highest ...</td>\n",
       "      <td>uae report 1007 new covid19 case high since ou...</td>\n",
       "      <td>64</td>\n",
       "      <td>bright side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>2.273830e+08</td>\n",
       "      <td>trump officials interfered with cdc reports on...</td>\n",
       "      <td>Trump officials interfered with CDC reports on...</td>\n",
       "      <td>trump official interfere cdc report covid19 po...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>1.304427e+18</td>\n",
       "      <td>6.874206e+07</td>\n",
       "      <td>why did twitter suddenly reinstate   could it ...</td>\n",
       "      <td>Why did Twitter suddenly reinstate @clif_high?...</td>\n",
       "      <td>twitter suddenly reinstate could science valid...</td>\n",
       "      <td>55</td>\n",
       "      <td>silver line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>1.304671e+18</td>\n",
       "      <td>8.323244e+17</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>Denna veckas COVID-19 veckorapport från Folkhä...</td>\n",
       "      <td>denna veckas covid19 veckorapport från folkhäl...</td>\n",
       "      <td>50</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6734</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>4.446656e+09</td>\n",
       "      <td>republicans defend trump after he admitted dow...</td>\n",
       "      <td>Republicans Defend Trump After He Admitted Dow...</td>\n",
       "      <td>republican defend trump admit downplay true th...</td>\n",
       "      <td>50</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6735</th>\n",
       "      <td>1.301853e+18</td>\n",
       "      <td>3.914277e+08</td>\n",
       "      <td>the recession on the back of the governments h...</td>\n",
       "      <td>The recession on the back of the Government's ...</td>\n",
       "      <td>the recession the back the government handle c...</td>\n",
       "      <td>50</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6736</th>\n",
       "      <td>1.304756e+18</td>\n",
       "      <td>2.215891e+09</td>\n",
       "      <td>65 catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 Catholics across the street only 7 wearing ...</td>\n",
       "      <td>65 catholic across the street 7 wear mask</td>\n",
       "      <td>50</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6737 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "0     1.304786e+18  9.053900e+07   \n",
       "1     1.304786e+18  8.497239e+17   \n",
       "2     1.304786e+18  1.293830e+18   \n",
       "3     1.304786e+18  1.188902e+18   \n",
       "4     1.304786e+18  2.273830e+08   \n",
       "...            ...           ...   \n",
       "6732  1.304427e+18  6.874206e+07   \n",
       "6733  1.304671e+18  8.323244e+17   \n",
       "6734  1.304768e+18  4.446656e+09   \n",
       "6735  1.301853e+18  3.914277e+08   \n",
       "6736  1.304756e+18  2.215891e+09   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     our intention is to make sure that evidence sc...   \n",
       "2     for more information contact us  mail  follow ...   \n",
       "3     uae reports 1007 new covid19 cases highest sin...   \n",
       "4     trump officials interfered with cdc reports on...   \n",
       "...                                                 ...   \n",
       "6732  why did twitter suddenly reinstate   could it ...   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...   \n",
       "6734  republicans defend trump after he admitted dow...   \n",
       "6735  the recession on the back of the governments h...   \n",
       "6736  65 catholics across the street only 7 wearing ...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "0     woke up to see if the justin bieber pandemic w...   \n",
       "1     @TeresaCCarter2 “Our intention is to make sure...   \n",
       "2     For More Information contact us. \\nMail:- digi...   \n",
       "3     UAE reports 1,007 new Covid-19 cases, highest ...   \n",
       "4     Trump officials interfered with CDC reports on...   \n",
       "...                                                 ...   \n",
       "6732  Why did Twitter suddenly reinstate @clif_high?...   \n",
       "6733  Denna veckas COVID-19 veckorapport från Folkhä...   \n",
       "6734  Republicans Defend Trump After He Admitted Dow...   \n",
       "6735  The recession on the back of the Government's ...   \n",
       "6736  65 Catholics across the street only 7 wearing ...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "0     woke to see the justin bieber pandemic go back...           55   \n",
       "1      intention to make sure evidence sciencebased ...           55   \n",
       "2     information contact u mail follow instagram gy...           55   \n",
       "3     uae report 1007 new covid19 case high since ou...           64   \n",
       "4     trump official interfere cdc report covid19 po...           55   \n",
       "...                                                 ...          ...   \n",
       "6732  twitter suddenly reinstate could science valid...           55   \n",
       "6733  denna veckas covid19 veckorapport från folkhäl...           50   \n",
       "6734  republican defend trump admit downplay true th...           50   \n",
       "6735  the recession the back the government handle c...           50   \n",
       "6736          65 catholic across the street 7 wear mask           50   \n",
       "\n",
       "     final_keyword_match  \n",
       "0            silver line  \n",
       "1            silver line  \n",
       "2            silver line  \n",
       "3            bright side  \n",
       "4            silver line  \n",
       "...                  ...  \n",
       "6732         silver line  \n",
       "6733                hope  \n",
       "6734                safe  \n",
       "6735                hope  \n",
       "6736                hope  \n",
       "\n",
       "[6737 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_pe['final_score'] = interim_pe['final_score'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>extended_tweet_full_text</th>\n",
       "      <th>extended_tweet_full_text_duplicate</th>\n",
       "      <th>final</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_keyword_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>3.190884e+08</td>\n",
       "      <td>happy saturday dear michael i wish you a wonde...</td>\n",
       "      <td>@mbsings Happy Saturday dear Michael, I wish y...</td>\n",
       "      <td>happy saturday dear michael wish wonderful rel...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.415685e+09</td>\n",
       "      <td>i really hope y’all are taking care of your sk...</td>\n",
       "      <td>I really hope y’all are taking care of your sk...</td>\n",
       "      <td>really hope  take care your skin wear mask als...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.062696e+18</td>\n",
       "      <td>i hope someone corrected her false narrative p...</td>\n",
       "      <td>@SteveGuest @realDonaldTrump I hope someone co...</td>\n",
       "      <td>hope someone correct false narrative president...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.302204e+18</td>\n",
       "      <td>lets hug each other and look at each others ey...</td>\n",
       "      <td>Let's hug each other and look at each other's ...</td>\n",
       "      <td>let hug look at others eye let sure to meet co...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1.304786e+18</td>\n",
       "      <td>1.304065e+18</td>\n",
       "      <td>im selling butterfly face mask extender  exten...</td>\n",
       "      <td>I'm selling Butterfly Face Mask Extender / Ext...</td>\n",
       "      <td>im sell butterfly face mask extender extension...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>1.304633e+18</td>\n",
       "      <td>3.099072e+08</td>\n",
       "      <td>the solidarity and camaraderie between  and um...</td>\n",
       "      <td>The solidarity and camaraderie between @geo355...</td>\n",
       "      <td>the solidarity camaraderie umich undergrad hug...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>1.304428e+18</td>\n",
       "      <td>5.671716e+08</td>\n",
       "      <td>do not travel to porthcawl in large numbers ov...</td>\n",
       "      <td>Do not travel to #Porthcawl in large numbers o...</td>\n",
       "      <td>do travel to porthcawl large number the weeken...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6629</th>\n",
       "      <td>1.304630e+18</td>\n",
       "      <td>5.064467e+08</td>\n",
       "      <td>you have a great community with dedicated play...</td>\n",
       "      <td>@eastlondonFGC You have a great community with...</td>\n",
       "      <td>great community dedicate player amaze to see o...</td>\n",
       "      <td>100</td>\n",
       "      <td>hope</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6646</th>\n",
       "      <td>1.304768e+18</td>\n",
       "      <td>1.501859e+07</td>\n",
       "      <td>hello to those who are just becoming aware of ...</td>\n",
       "      <td>Hello to those who are just becoming aware of ...</td>\n",
       "      <td>hello to become aware active russian agent her...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6692</th>\n",
       "      <td>1.304505e+18</td>\n",
       "      <td>2.185707e+07</td>\n",
       "      <td>fixed penalty notices fpn have been served aft...</td>\n",
       "      <td>Fixed penalty notices (FPN) have been served a...</td>\n",
       "      <td>fix penalty notice fpn serve wedding party bol...</td>\n",
       "      <td>100</td>\n",
       "      <td>safe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id       user_id  \\\n",
       "80    1.304786e+18  3.190884e+08   \n",
       "95    1.304786e+18  1.415685e+09   \n",
       "113   1.304786e+18  1.062696e+18   \n",
       "115   1.304786e+18  1.302204e+18   \n",
       "134   1.304786e+18  1.304065e+18   \n",
       "...            ...           ...   \n",
       "6476  1.304633e+18  3.099072e+08   \n",
       "6503  1.304428e+18  5.671716e+08   \n",
       "6629  1.304630e+18  5.064467e+08   \n",
       "6646  1.304768e+18  1.501859e+07   \n",
       "6692  1.304505e+18  2.185707e+07   \n",
       "\n",
       "                               extended_tweet_full_text  \\\n",
       "80    happy saturday dear michael i wish you a wonde...   \n",
       "95    i really hope y’all are taking care of your sk...   \n",
       "113   i hope someone corrected her false narrative p...   \n",
       "115   lets hug each other and look at each others ey...   \n",
       "134   im selling butterfly face mask extender  exten...   \n",
       "...                                                 ...   \n",
       "6476  the solidarity and camaraderie between  and um...   \n",
       "6503  do not travel to porthcawl in large numbers ov...   \n",
       "6629  you have a great community with dedicated play...   \n",
       "6646  hello to those who are just becoming aware of ...   \n",
       "6692  fixed penalty notices fpn have been served aft...   \n",
       "\n",
       "                     extended_tweet_full_text_duplicate  \\\n",
       "80    @mbsings Happy Saturday dear Michael, I wish y...   \n",
       "95    I really hope y’all are taking care of your sk...   \n",
       "113   @SteveGuest @realDonaldTrump I hope someone co...   \n",
       "115   Let's hug each other and look at each other's ...   \n",
       "134   I'm selling Butterfly Face Mask Extender / Ext...   \n",
       "...                                                 ...   \n",
       "6476  The solidarity and camaraderie between @geo355...   \n",
       "6503  Do not travel to #Porthcawl in large numbers o...   \n",
       "6629  @eastlondonFGC You have a great community with...   \n",
       "6646  Hello to those who are just becoming aware of ...   \n",
       "6692  Fixed penalty notices (FPN) have been served a...   \n",
       "\n",
       "                                                  final  final_score  \\\n",
       "80    happy saturday dear michael wish wonderful rel...          100   \n",
       "95    really hope  take care your skin wear mask als...          100   \n",
       "113   hope someone correct false narrative president...          100   \n",
       "115   let hug look at others eye let sure to meet co...          100   \n",
       "134   im sell butterfly face mask extender extension...          100   \n",
       "...                                                 ...          ...   \n",
       "6476  the solidarity camaraderie umich undergrad hug...          100   \n",
       "6503  do travel to porthcawl large number the weeken...          100   \n",
       "6629  great community dedicate player amaze to see o...          100   \n",
       "6646  hello to become aware active russian agent her...          100   \n",
       "6692  fix penalty notice fpn serve wedding party bol...          100   \n",
       "\n",
       "     final_keyword_match  \n",
       "80                  hope  \n",
       "95                  hope  \n",
       "113                 hope  \n",
       "115                 hope  \n",
       "134                 hope  \n",
       "...                  ...  \n",
       "6476                safe  \n",
       "6503                safe  \n",
       "6629                hope  \n",
       "6646                safe  \n",
       "6692                safe  \n",
       "\n",
       "[214 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interim_pe[interim_pe['final_score'] == 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "interim_pe[interim_pe['final_score'] == 100].to_csv('interim_pe.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
